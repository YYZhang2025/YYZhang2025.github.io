<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yuyang Zhang">
<meta name="description" content="在这篇文章中，我们将探索一系列的Qwen模型，沿着Qwen模型的发展时，来看看不同时期的Qwen模型运用了怎么样的不同的技术">

<title>Qwen Model Series</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<link href="../../../.././style/icon.avif" rel="icon">
<script src="../../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-0348920b7671f696dc9078d39bff215e.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-250da2873d24a44421c68a14153694c9.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../../site_libs/bootstrap/bootstrap-dark-691cf8fecc09a563af4b8b275f310845.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../../site_libs/bootstrap/bootstrap-250da2873d24a44421c68a14153694c9.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<link href="../../../../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="https://fonts.cdnfonts.com/css/cmu-sans-serif" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../../style/styles.css">
<link rel="stylesheet" href="../../../../style/callout.css">
<meta property="og:title" content="Qwen Model Series">
<meta property="og:description" content="在这篇文章中，我们将探索一系列的Qwen模型，沿着Qwen模型的发展时，来看看不同时期的Qwen模型运用了怎么样的不同的技术">
<meta property="og:image" content="assets/Qwen-Qwen1-Models.png">
</head>

<body class="nav-sidebar docked nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../index.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/YYZhang2025"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/zhang-yuyang/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../posts/Blogs/blogs_index.html"> 
<span class="menu-text">Blogs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../posts/Projects/projects_index.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../posts/PapersWithCode/100_Papers_index.html"> 
<span class="menu-text">100 Papers with Code</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-learning-notes" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Learning Notes</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-learning-notes">    
        <li>
    <a class="dropdown-item" href="../../../../posts/LearningNotes/CS336/index.html">
 <span class="dropdown-text">Stanford CS336: LLM from Scratch</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../../posts/LearningNotes/DLFaC/index.html">
 <span class="dropdown-text">Deep Learning Foundation and Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../../posts/LearningNotes/LLM-Series/index.html">
 <span class="dropdown-text">LLM Model Series</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title">Qwen Model Series</h1>
        </a>     
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="1">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#preliminary" id="toc-preliminary" class="nav-link active" data-scroll-target="#preliminary"><span class="header-section-number">1</span> Preliminary</a></li>
  <li><a href="#qwen1" id="toc-qwen1" class="nav-link" data-scroll-target="#qwen1"><span class="header-section-number">2</span> Qwen1</a>
  <ul>
  <li><a href="#tokenization" id="toc-tokenization" class="nav-link" data-scroll-target="#tokenization"><span class="header-section-number">2.1</span> Tokenization</a></li>
  <li><a href="#architecture" id="toc-architecture" class="nav-link" data-scroll-target="#architecture"><span class="header-section-number">2.2</span> Architecture</a></li>
  <li><a href="#pre-training" id="toc-pre-training" class="nav-link" data-scroll-target="#pre-training"><span class="header-section-number">2.3</span> Pre-Training</a></li>
  <li><a href="#extend-context-length" id="toc-extend-context-length" class="nav-link" data-scroll-target="#extend-context-length"><span class="header-section-number">2.4</span> Extend Context Length</a>
  <ul>
  <li><a href="#ntk-aware-interpolation" id="toc-ntk-aware-interpolation" class="nav-link" data-scroll-target="#ntk-aware-interpolation"><span class="header-section-number">2.4.1</span> NTK-aware Interpolation</a></li>
  <li><a href="#attention" id="toc-attention" class="nav-link" data-scroll-target="#attention"><span class="header-section-number">2.4.2</span> Attention</a></li>
  </ul></li>
  <li><a href="#alignment" id="toc-alignment" class="nav-link" data-scroll-target="#alignment"><span class="header-section-number">2.5</span> Alignment</a>
  <ul>
  <li><a href="#supervised-fine-tuning" id="toc-supervised-fine-tuning" class="nav-link" data-scroll-target="#supervised-fine-tuning"><span class="header-section-number">2.5.1</span> Supervised Fine-Tuning</a>
  <ul class="collapse">
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data"><span class="header-section-number">2.5.1.1</span> Data</a></li>
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training"><span class="header-section-number">2.5.1.2</span> Training</a></li>
  </ul></li>
  <li><a href="#rlhf" id="toc-rlhf" class="nav-link" data-scroll-target="#rlhf"><span class="header-section-number">2.5.2</span> RLHF</a>
  <ul class="collapse">
  <li><a href="#reward-model-training" id="toc-reward-model-training" class="nav-link" data-scroll-target="#reward-model-training"><span class="header-section-number">2.5.2.1</span> Reward Model Training</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#code-qwen" id="toc-code-qwen" class="nav-link" data-scroll-target="#code-qwen"><span class="header-section-number">2.6</span> Code Qwen</a></li>
  <li><a href="#math-qwen" id="toc-math-qwen" class="nav-link" data-scroll-target="#math-qwen"><span class="header-section-number">2.7</span> Math Qwen</a></li>
  <li><a href="#qwen-1-summary" id="toc-qwen-1-summary" class="nav-link" data-scroll-target="#qwen-1-summary"><span class="header-section-number">2.8</span> Qwen 1 Summary</a></li>
  </ul></li>
  <li><a href="#qwen1-vl" id="toc-qwen1-vl" class="nav-link" data-scroll-target="#qwen1-vl"><span class="header-section-number">3</span> Qwen1-VL</a>
  <ul>
  <li><a href="#model-architecture" id="toc-model-architecture" class="nav-link" data-scroll-target="#model-architecture"><span class="header-section-number">3.1</span> Model Architecture</a></li>
  <li><a href="#training-1" id="toc-training-1" class="nav-link" data-scroll-target="#training-1"><span class="header-section-number">3.2</span> Training</a>
  <ul>
  <li><a href="#pre-training-1" id="toc-pre-training-1" class="nav-link" data-scroll-target="#pre-training-1"><span class="header-section-number">3.2.0.1</span> Pre-Training</a></li>
  <li><a href="#multi-task-pre-training" id="toc-multi-task-pre-training" class="nav-link" data-scroll-target="#multi-task-pre-training"><span class="header-section-number">3.2.0.2</span> Multi-Task Pre-Training</a></li>
  <li><a href="#supervised-finetuning" id="toc-supervised-finetuning" class="nav-link" data-scroll-target="#supervised-finetuning"><span class="header-section-number">3.2.0.3</span> Supervised Finetuning</a></li>
  </ul></li>
  <li><a href="#qwen1-vl-sumary" id="toc-qwen1-vl-sumary" class="nav-link" data-scroll-target="#qwen1-vl-sumary"><span class="header-section-number">3.3</span> Qwen1-VL Sumary</a></li>
  </ul></li>
  <li><a href="#qwen1.5-moe" id="toc-qwen1.5-moe" class="nav-link" data-scroll-target="#qwen1.5-moe"><span class="header-section-number">4</span> Qwen1.5-MoE</a></li>
  <li><a href="#qwen2" id="toc-qwen2" class="nav-link" data-scroll-target="#qwen2"><span class="header-section-number">5</span> Qwen2</a>
  <ul>
  <li><a href="#tokenizer" id="toc-tokenizer" class="nav-link" data-scroll-target="#tokenizer"><span class="header-section-number">5.1</span> Tokenizer</a></li>
  <li><a href="#architecture-1" id="toc-architecture-1" class="nav-link" data-scroll-target="#architecture-1"><span class="header-section-number">5.2</span> Architecture</a>
  <ul>
  <li><a href="#dense-model" id="toc-dense-model" class="nav-link" data-scroll-target="#dense-model"><span class="header-section-number">5.2.1</span> Dense Model</a>
  <ul class="collapse">
  <li><a href="#gouged-query-attention" id="toc-gouged-query-attention" class="nav-link" data-scroll-target="#gouged-query-attention"><span class="header-section-number">5.2.1.1</span> Gouged Query Attention</a></li>
  <li><a href="#dual-chunk-attention-with-yarn" id="toc-dual-chunk-attention-with-yarn" class="nav-link" data-scroll-target="#dual-chunk-attention-with-yarn"><span class="header-section-number">5.2.1.2</span> Dual Chunk Attention with YARN</a></li>
  </ul></li>
  <li><a href="#mixture-of-expert-model" id="toc-mixture-of-expert-model" class="nav-link" data-scroll-target="#mixture-of-expert-model"><span class="header-section-number">5.2.2</span> Mixture-Of-Expert Model</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#qwen2-vl" id="toc-qwen2-vl" class="nav-link" data-scroll-target="#qwen2-vl"><span class="header-section-number">6</span> Qwen2-VL</a>
  <ul>
  <li><a href="#architecture-2" id="toc-architecture-2" class="nav-link" data-scroll-target="#architecture-2"><span class="header-section-number">6.1</span> Architecture</a>
  <ul>
  <li><a href="#naive-dynamic-resolution" id="toc-naive-dynamic-resolution" class="nav-link" data-scroll-target="#naive-dynamic-resolution"><span class="header-section-number">6.1.1</span> Naive Dynamic Resolution</a></li>
  <li><a href="#multi-modal-rotary-position-embedding-m-rope" id="toc-multi-modal-rotary-position-embedding-m-rope" class="nav-link" data-scroll-target="#multi-modal-rotary-position-embedding-m-rope"><span class="header-section-number">6.1.2</span> Multi-Modal Rotary Position Embedding (M-RoPE)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#qwen2.5" id="toc-qwen2.5" class="nav-link" data-scroll-target="#qwen2.5"><span class="header-section-number">7</span> Qwen2.5</a></li>
  <li><a href="#qwen2.5-vl" id="toc-qwen2.5-vl" class="nav-link" data-scroll-target="#qwen2.5-vl"><span class="header-section-number">8</span> Qwen2.5-VL</a></li>
  <li><a href="#qwen3" id="toc-qwen3" class="nav-link" data-scroll-target="#qwen3"><span class="header-section-number">9</span> Qwen3</a></li>
  <li><a href="#qwen3-vl" id="toc-qwen3-vl" class="nav-link" data-scroll-target="#qwen3-vl"><span class="header-section-number">10</span> QWen3-VL</a></li>
  <li><a href="#qwen-next" id="toc-qwen-next" class="nav-link" data-scroll-target="#qwen-next"><span class="header-section-number">11</span> Qwen-NEXT</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Qwen Model Series</h1>
  <div class="quarto-categories">
    <div class="quarto-category">LLM</div>
    <div class="quarto-category">Multi-Modality</div>
  </div>
  </div>

<div>
  <div class="description">
    在这篇文章中，我们将探索一系列的Qwen模型，沿着Qwen模型的发展时，来看看不同时期的Qwen模型运用了怎么样的不同的技术
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Yuyang Zhang </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="preliminary" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Preliminary</h1>
<p>在了解 Qwen 等LLM 模型前，我们需要先了解什么是 <a href="../../01-transformer/Transformer.qmd">Transformer</a>, 在这里就不具体展开了，有兴趣的同学前去查看 <a href="../../01-transformer/Transformer.qmd">这篇文章</a>。 对于Multi-Modality的Qwen，我们需要具备的是 <a href="../../02-vision-transformer/Vision-Transformer.qmd">Vision-Transformer</a> 的知识。</p>
<p>前置知识：</p>
<ul>
<li><a href="../../01-transformer/Transformer.qmd">Transformer</a></li>
<li><a href="../../02-vision-transformer/Vision-Transformer.qmd">Vision-Transformer</a></li>
</ul>
<p>Qwen（通义千问） 是阿里云旗下达摩院推出的一系列<strong>大语言模型（LLM)</strong> 与<strong>多模态模型（M-LLM）</strong>。它类似 OpenAI 的 GPT 系列，是阿里打造的全栈式统一LLM体系。 接下来，我们来沿着Qwen模型发展的时间线，来感受一下LLM发展的过程。</p>
</section>
<section id="qwen1" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Qwen1</h1>
<p>Qwen系列是阿里团队与2023年8月发布的LLM模型， Qwen 模型和其他的LLM类似，都有3个阶段的training:</p>
<ul>
<li>Pre-training</li>
<li>Supervised Finetuning(SFT)</li>
<li>Reinforcement Learning with human feedback (RLHF)</li>
</ul>
<blockquote class="blockquote">
<p>The model series include the base pretrained language models, chat models finetuned with human alignment techniques, i.e., supervised finetuning (SFT), reinforcement learning with human feedback (RLHF), etc., as well as specialized models in coding and math. <cite> QWEN TECHNICAL REPORT, p.3 </cite> <img src="assets/Qwen-Qwen1-Models.png" class="img-fluid"></p>
</blockquote>
<section id="tokenization" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="tokenization"><span class="header-section-number">2.1</span> Tokenization</h2>
<p>Qwen 用byte pair encoding (BPE)的Tokenization的方法，这与GPT-3.5，GPT-4系列是一样的。在训练Tokenization之后，最后的Vocabulary Size 由152K。 Qwen的Tokenization的方法，实现了较低的Compression Ratio。低Compression Ratio说明了Qwen在这些语言的Training 和 Inference 中会比较高效。</p>
<p><img src="assets/Qwen- Qwen1-Tokenization-Compression-Ratio.png" class="img-fluid"></p>
</section>
<section id="architecture" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="architecture"><span class="header-section-number">2.2</span> Architecture</h2>
<p>Qwen-1 的模型借鉴了LLaMA模型，也是Decoder-Only 的 Transformer <span class="citation" data-cites="AttentionAllYou2023vaswani">(<a href="#ref-AttentionAllYou2023vaswani" role="doc-biblioref">Vaswani et al. 2023</a>)</span> 模型，只不过有着以下几点的改变：</p>
<ul>
<li>Embedding and output projection: LLaMA和Transformer 都用了Weight Tying的技术，这种方式可以减少模型的参数，提高训练的效率。不过Qwen没有沿用这种方式，而是让这两个有各自的parameters。</li>
<li>Positional Embedding： Qwen用了 RoPE <span class="citation" data-cites="RoFormerEnhancedTransformer2023su">(<a href="#ref-RoFormerEnhancedTransformer2023su" role="doc-biblioref">Su et al. 2023</a>)</span> 来Encoding Position消息，同时运用了 <code>FP32</code> 的精度，来 inverse frequency matrix.</li>
<li>Bias: 对于许多的Layer，移除了bias的term，不过对于QKV Layers，还是加了Bias。</li>
<li>Pre-Norm &amp; RMSNorm：Qwen 模型用了 Pre-Norm 和RMSNorm来当作Normalization 的方法</li>
<li>Activation Function: 用了SwiGLU当作Activation Function, 为了保持模型参数的不变，减少了d_ff到 <span class="math inline">\(\frac{8}{3}\)</span></li>
</ul>
<p><img src="assets/Qwen-Qwen1-Model-Architecture.png" class="img-fluid"></p>
</section>
<section id="pre-training" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="pre-training"><span class="header-section-number">2.3</span> Pre-Training</h2>
<p>Pre-Training 遵循了标准的Auto-Regressive LM的训练目标，Context Length设为2048， 运用了Flash-Attention。 利用AdamW 的optimizer。 和 Cosine Learning Rate schedule. 并且运用了 Mixed Precision Training 为了提高模型的Stability 和 训练速度。</p>
</section>
<section id="extend-context-length" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="extend-context-length"><span class="header-section-number">2.4</span> Extend Context Length</h2>
<p>模型在训练时的Context Length设为了2048，不过这在Inference时，是不够的。于是Qwen利用了一种training-free techniques 的方法， NTK-aware interpolation</p>
<section id="ntk-aware-interpolation" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="ntk-aware-interpolation"><span class="header-section-number">2.4.1</span> NTK-aware Interpolation</h3>
<p>NTK-aware Interpolation 与普通的Position Interpolation不同，NTK-aware Interpolation adjust the base of RoPE。 Qwen的团队在NTK-aware的基础上，为了更好的压榨出NTK的性能，实现了一个NTK的extension，叫做 dynamic NTK-aware interpolation。</p>
</section>
<section id="attention" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="attention"><span class="header-section-number">2.4.2</span> Attention</h3>
<p>除了Position Encoding，attention的计算效率也是阻碍Context length的原因之一。 Qwen的团队用了两个Attention的技巧： - LogN-Scaling - Layer-wise Window Attention: 不同的Layer 有不同的Window Size</p>
<blockquote class="blockquote">
<p>We also observed that the long-context modeling ability of our model varies across layers, with lower layers being more sensitive in context length extension compared to the higher layers. To leverage this observation, we assign different window sizes to each layer, using shorter windows for lower layers and longer windows for higher layers. <cite> QWEN TECHNICAL REPORT, p.8 </cite></p>
</blockquote>
<p>运用了以上几个技巧之后，Qwen 模型将context length 从2048提升到了8192， 在没有损害模型能力的前提下。</p>
</section>
</section>
<section id="alignment" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="alignment"><span class="header-section-number">2.5</span> Alignment</h2>
<p>在Pre-train Qwen之后，我们不能直接使用，</p>
<section id="supervised-fine-tuning" class="level3" data-number="2.5.1">
<h3 data-number="2.5.1" class="anchored" data-anchor-id="supervised-fine-tuning"><span class="header-section-number">2.5.1</span> Supervised Fine-Tuning</h3>
<p>SFT的训练，可以让Qwen模型遵循Chat类型的回答。</p>
<section id="data" class="level4" data-number="2.5.1.1">
<h4 data-number="2.5.1.1" class="anchored" data-anchor-id="data"><span class="header-section-number">2.5.1.1</span> Data</h4>
<div class="sourceCode" id="cb1" data-code-line-numbers=""><pre class="sourceCode numberSource json number-lines code-with-copy"><code class="sourceCode json"><span id="cb1-1"><a href="#cb1-1"></a><span class="fu">{</span></span>
<span id="cb1-2"><a href="#cb1-2"></a>  <span class="dt">"messages"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="cb1-3"><a href="#cb1-3"></a>    <span class="fu">{</span><span class="dt">"role"</span><span class="fu">:</span> <span class="st">"system"</span><span class="fu">,</span> <span class="dt">"content"</span><span class="fu">:</span> <span class="st">"You are a helpful, harmless and honest assistant."</span><span class="fu">}</span><span class="ot">,</span></span>
<span id="cb1-4"><a href="#cb1-4"></a>    <span class="fu">{</span><span class="dt">"role"</span><span class="fu">:</span> <span class="st">"user"</span><span class="fu">,</span> <span class="dt">"content"</span><span class="fu">:</span> <span class="st">"帮我写一段关于Qwen模型的简介。"</span><span class="fu">}</span><span class="ot">,</span></span>
<span id="cb1-5"><a href="#cb1-5"></a>    <span class="fu">{</span><span class="dt">"role"</span><span class="fu">:</span> <span class="st">"assistant"</span><span class="fu">,</span> <span class="dt">"content"</span><span class="fu">:</span> <span class="st">"Qwen 是阿里云推出的一系列大语言模型..."</span><span class="fu">}</span></span>
<span id="cb1-6"><a href="#cb1-6"></a>  <span class="ot">]</span></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="training" class="level4" data-number="2.5.1.2">
<h4 data-number="2.5.1.2" class="anchored" data-anchor-id="training"><span class="header-section-number">2.5.1.2</span> Training</h4>
<p>与Pre-Training类似，SFT 用了相同的训练目标 Next-Token Prediction，不过与Pre-Training不同的是，SFT用了一个Loss Mask来mask掉system 和 user inputs。</p>
<p>同样运用了 AdamW optimizer</p>
</section>
</section>
<section id="rlhf" class="level3" data-number="2.5.2">
<h3 data-number="2.5.2" class="anchored" data-anchor-id="rlhf"><span class="header-section-number">2.5.2</span> RLHF</h3>
<p>在SFT之后，模型可能overfitting，并且缺少generalization 和 creativity。 为了让模型获得这些能力，在SFT之后，我们需要RLHF，这个过程涉及到两个步骤： 1. Reward Model Training 2. Policy Training</p>
<section id="reward-model-training" class="level4" data-number="2.5.2.1">
<h4 data-number="2.5.2.1" class="anchored" data-anchor-id="reward-model-training"><span class="header-section-number">2.5.2.1</span> Reward Model Training</h4>
<p>Reward Model Training 也叫做 Preference Model Pretraining (PMP)， 这个同样需要pre- training 然后Fine-Tunining。 PMP 的训练数据, 也是由一系列的comparison data 组成。</p>
<div class="sourceCode" id="cb2" data-code-line-numbers=""><pre class="sourceCode numberSource json number-lines code-with-copy"><code class="sourceCode json"><span id="cb2-1"><a href="#cb2-1"></a><span class="fu">{</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>  <span class="dt">"prompt"</span><span class="fu">:</span> <span class="st">"Explain why the Earth has seasons."</span><span class="fu">,</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>  <span class="dt">"chosen"</span><span class="fu">:</span> <span class="st">"The Earth has seasons because its axis is tilted about 23.5 degrees. As the planet orbits the Sun, this tilt causes different hemispheres to receive more or less direct sunlight throughout the year, creating seasonal temperature and daylight changes."</span><span class="fu">,</span></span>
<span id="cb2-4"><a href="#cb2-4"></a>  <span class="dt">"rejected"</span><span class="fu">:</span> <span class="st">"The Earth has seasons because sometimes it randomly moves closer to the Sun and sometimes farther away."</span></span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>训练这个Reward Model。 Qwen的团队用了Pre-trained Language Model 也就是Qwen， 来当作Initiate 权重。 在这个Qwen模型之上，加上了一层Pooling Layer来提取出 Reward （一个Scalar Value） #### Policy Training</p>
<p>在训练完Reward Model之后，下一步就是运用Reinforcement的算法来训练LLM。Qwen的团队运用了PPO的算法，来训练，这个算法由4个部分： - Policy Model - Value Model - Reference Model - Reward Model</p>
<p>至此，Qwen的Foundation Model，以及训练结束了。接下来可以通过不同的训练数据，让Qwen 获得不同的能力，比如Code-Qwen，以及Math-Qwen</p>
</section>
</section>
</section>
<section id="code-qwen" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="code-qwen"><span class="header-section-number">2.6</span> Code Qwen</h2>
</section>
<section id="math-qwen" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="math-qwen"><span class="header-section-number">2.7</span> Math Qwen</h2>
</section>
<section id="qwen-1-summary" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="qwen-1-summary"><span class="header-section-number">2.8</span> Qwen 1 Summary</h2>
</section>
</section>
<section id="qwen1-vl" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Qwen1-VL</h1>
<p>训练完Qwen1 之后，Qwen团队发布了Qwen-VL 的多模态大语言模型。 Qwen-VLs是基于Qwen-7B的大语言模型，在此基础上添加了 visual receptor，其中包含了 Language- aligned encoder和position aware adapter。通过3-stage pre-training来让LLM获得Visual的能力。Qwen-VL-Chat是在Qwen-VL的基础上，通过instruction-data，来使得它可以获得对话的能力。</p>
<blockquote class="blockquote">
<p>Qwen-VLs are a series of highly performant and versatile vision-language foundation models based on Qwen-7B (Qwen, 2023) language model. We empower the LLM basement with visual capacity by introducing a new visual receptor including a language-aligned visual encoder and a positionaware adapter. <cite> Qwen-VL- A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond, p.3 </cite></p>
</blockquote>
<section id="model-architecture" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="model-architecture"><span class="header-section-number">3.1</span> Model Architecture</h2>
<p>Qwen-VL的模型主要包含了以下几个组件： - Large Language Model： Qwen-VL是基于之前的 Qwen-7B来当作大语言组件 - Visual Encoder： Visual Encoder的结构是，与 <a href="../../02-vision-transformer/Vision-Transformer.qmd">Vision-Transformer</a> <span class="citation" data-cites="ImageWorth16x162021dosovitskiy">(<a href="#ref-ImageWorth16x162021dosovitskiy" role="doc-biblioref">Dosovitskiy et al. 2021</a>)</span> 的结构是一样的。通过加载 OpenCLIP的权重, 来初始化ViT - Position-aware Vision-Language Adapter: 为了减少 image feature的长度，Qwen-VL 利用了 Vision Language Adapter. 这个是一组Cross-Attention Module 随机初始化，这种方法将Visual Feature的长度，压缩到了256. 在这个Adapter 中，2D absolute positional encoding 也添加了进来，用来减少可能消息的丢失。</p>
<p><img src="assets/Qwen-QwenVL-position-aware-vision-length.png" class="img-fluid"> ## Inputs and Outputs 添加了Visual Tokens之后，模型需要一种方法，来辨别出哪些是Visual Tokens, 哪些是Text Tokens</p>
<blockquote class="blockquote">
<p>Images are processed through the visual encoder and adapter, yielding fixed-length sequences of image features. To differentiate between image feature input and text feature input, two special tokens (<img> and ) are appended to the beginning and end of the image feature sequence respectively, signifying the start and end of image content <cite> Qwen-VL- A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond, p.4 </cite></p>
</blockquote>
<p>对于不同的输入和要求，模型的输出的内容是不一样的。 <img src="assets/Qwen-QwenVl-example-training-data.png" class="img-fluid"></p>
</section>
<section id="training-1" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="training-1"><span class="header-section-number">3.2</span> Training</h2>
<p>Qwen-VL 的训练分为以下几个步骤，如下图所示：</p>
<p><img src="assets/Qwen-Qwen1VL.png" class="img-fluid"></p>
<section id="pre-training-1" class="level4" data-number="3.2.0.1">
<h4 data-number="3.2.0.1" class="anchored" data-anchor-id="pre-training-1"><span class="header-section-number">3.2.0.1</span> Pre-Training</h4>
<p>在这个阶段，模型训练出认识图片的能力，冻结了LLM，训练ViT和VL adapter。</p>
</section>
<section id="multi-task-pre-training" class="level4" data-number="3.2.0.2">
<h4 data-number="3.2.0.2" class="anchored" data-anchor-id="multi-task-pre-training"><span class="header-section-number">3.2.0.2</span> Multi-Task Pre-Training</h4>
<p>在这个阶段，模型已经有了对Image的基本认知，接下来就是训练模型对于不同要求的输出，也就是所谓的Multi-Task。 在这个阶段，所有的权重，都进行微调。通过这个训练，模型获得了完成不同任务的能力。</p>
</section>
<section id="supervised-finetuning" class="level4" data-number="3.2.0.3">
<h4 data-number="3.2.0.3" class="anchored" data-anchor-id="supervised-finetuning"><span class="header-section-number">3.2.0.3</span> Supervised Finetuning</h4>
<p>在这个阶段下，Qwen团队训练了Qwen-VL，使它获得Instruction- Following的能力。 也就是Qwen-VL-Chat Model，</p>
<p>Supervised Finetuning 的数据如下图所示： <img src="assets/Qwen-QwenVL-Chat-Data.png" class="img-fluid"></p>
<p>至此，Qwen-VL的训练已经结束了，</p>
</section>
</section>
<section id="qwen1-vl-sumary" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="qwen1-vl-sumary"><span class="header-section-number">3.3</span> Qwen1-VL Sumary</h2>
</section>
</section>
<section id="qwen1.5-moe" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Qwen1.5-MoE</h1>
<p>2024年2月份，Qwen 团队发布了Qwen1.5的模型，以及Qwen1.5-MoE 模型，这个是Qwen的首个MoE的模型。对于Qwen1.5 模型，Qwen团队没有专门的Technical Report来介绍Qwen1.5， 只有一个基本的<a href="https://qwenlm.github.io/blog/qwen1.5/">Blog</a>，来介绍。 Qwen1.5 模型可以支持32768 tokens. 相对于Qwen1 有了极大的提升。<a href="https://qwenlm.github.io/blog/qwen-moe/">Qwen1.5-MoE</a> 是Qwen的首个MoE模型，Qwen1.5-MoE（Mixture-of-Experts）模型在传统 MoE 架构的基础上进行了多项关键性改进，目标是在 不显著增加参数量的前提下提升性能、训练稳定性与算力效率。相比 Mixtral 等经典实现，Qwen1.5-MoE 对 expert 设计、初始化策略、routing 机制 做了系统优化</p>
</section>
<section id="qwen2" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Qwen2</h1>
<p>仅在几个月之后，2024年的6月份，Qwen发布了全新的Qwen2 模型， Qwen2 模型了包含了 0.5 billion, 1.5 billion, 7 billion, and 72 billion, plus a Mixture-of-Experts (MoE) model with 57 billion parameters, of which 14 billion are activated for each token.</p>
<section id="tokenizer" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="tokenizer"><span class="header-section-number">5.1</span> Tokenizer</h2>
<p>Qwen2 的Tokenization的方法，与Qwen1 是一样的，都采用了BPE Tokenization Algorithms。Vocabulary Size 有151,643 Regular tokens和3 个control tokens。</p>
</section>
<section id="architecture-1" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="architecture-1"><span class="header-section-number">5.2</span> Architecture</h2>
<p>与Qwen1 相比，Qwen2 的模型改动并没有很大，主要体现在以下几个方面</p>
<section id="dense-model" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="dense-model"><span class="header-section-number">5.2.1</span> Dense Model</h3>
<section id="gouged-query-attention" class="level4" data-number="5.2.1.1">
<h4 data-number="5.2.1.1" class="anchored" data-anchor-id="gouged-query-attention"><span class="header-section-number">5.2.1.1</span> Gouged Query Attention</h4>
<p>运用了Grouped Query Attention, 这种方式可以优化KV Cache</p>
</section>
<section id="dual-chunk-attention-with-yarn" class="level4" data-number="5.2.1.2">
<h4 data-number="5.2.1.2" class="anchored" data-anchor-id="dual-chunk-attention-with-yarn"><span class="header-section-number">5.2.1.2</span> Dual Chunk Attention with YARN</h4>
<p>运用了Dual Chunk Attention 和 YARN 来提高Context 的长度。</p>
</section>
</section>
<section id="mixture-of-expert-model" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="mixture-of-expert-model"><span class="header-section-number">5.2.2</span> Mixture-Of-Expert Model</h3>
</section>
</section>
</section>
<section id="qwen2-vl" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Qwen2-VL</h1>
<p>在介绍完Qwen2之后，接下来自然而来就是Qwen2-VL 模型。Qwen2-VL 在Qwen1-VL模型上，有了较大的提升，其中一个主要的就是：支持任何大小的图片和Video。接下来让我们看看模型的架构：</p>
<section id="architecture-2" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="architecture-2"><span class="header-section-number">6.1</span> Architecture</h2>
<p><img src="assets/Qwen-Qwen2-Vl-architecture.png" class="img-fluid"></p>
<section id="naive-dynamic-resolution" class="level3" data-number="6.1.1">
<h3 data-number="6.1.1" class="anchored" data-anchor-id="naive-dynamic-resolution"><span class="header-section-number">6.1.1</span> Naive Dynamic Resolution</h3>
<p>Naive Dynamic Resolution 在 NaViT <span class="citation" data-cites="PatchPackNaViT2023dehghani">(<a href="#ref-PatchPackNaViT2023dehghani" role="doc-biblioref">Dehghani et al. 2023</a>)</span> 中提出，它可以让Vision Transformer 在不同长度的图片中训练。</p>
<p>除此之外，Qwen2-VL 摒弃了Absolute Position Embedding，转用2D-RoPE <span class="citation" data-cites="RoFormerEnhancedTransformer2023su">(<a href="#ref-RoFormerEnhancedTransformer2023su" role="doc-biblioref">Su et al. 2023</a>)</span>, 除此之外，在ViT 生成Representation之后，Qwen2-VL 还在之后添加了一层MLPLayer，它的作用是减少Tokens的数量，通过临近的 <span class="math inline">\(2\times 2\)</span> 的tokens，MLP讲这些tokens merge在一起，将Tokens的数量减少了 4 倍。比如一张 <span class="math inline">\(224 \times 224\)</span> 的图片, 分成大小为14的patches，得到了256 个tokens，将这些tokens merge在一起，我们就得到了 64 个tokens。</p>
</section>
<section id="multi-modal-rotary-position-embedding-m-rope" class="level3" data-number="6.1.2">
<h3 data-number="6.1.2" class="anchored" data-anchor-id="multi-modal-rotary-position-embedding-m-rope"><span class="header-section-number">6.1.2</span> Multi-Modal Rotary Position Embedding (M-RoPE)</h3>
<p><img src="assets/Qwen=-Qwen2VL-M-RoPE.png" class="img-fluid">Qwen2-VL 利用M-RoPE来提取出不同Modality之间的position 的信息。 通过将Rotary Embedding 分解成： - Temporal - Height - Width 三个部分。 对于Text 的部分，这几个部分会得到相同的IDs，这使得它可以类似于1D-RoPE的作用。对于图片的输入，Temporal 部分的ID保持不变，Height 和 Width的部分，会得到不同的IDs。 对于视频的输入，Temporal，Height，Width都会改变。</p>
<blockquote class="blockquote">
<p>M-RoPE not only enhances the modeling of positional information but also reduces the value of position IDs for images and videos, enabling the model to extrapolate to longer sequences during inference. <cite> Qwen -VL- Enhancing Vision-Language Model’s Perception of the World at Any Resolution, p.5 </cite></p>
</blockquote>
<ul>
<li>For text, these three use identical position IDs → equivalent to standard 1D RoPE.</li>
<li>For images, temporal ID is constant; height &amp; width IDs encode patch position.</li>
<li>For videos, temporal ID increases per frame; height &amp; width same as image.</li>
</ul>
</section>
</section>
</section>
<section id="qwen2.5" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Qwen2.5</h1>
</section>
<section id="qwen2.5-vl" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Qwen2.5-VL</h1>
<p><img src="assets/Qwen-Qwen2.5-VL-Architecture.png" class="img-fluid"></p>
</section>
<section id="qwen3" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Qwen3</h1>
</section>
<section id="qwen3-vl" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> QWen3-VL</h1>
<p><img src="assets/Qwen-Qwen3VL-Architecture.png" class="img-fluid"></p>
</section>
<section id="qwen-next" class="level1" data-number="11">
<h1 data-number="11"><span class="header-section-number">11</span> Qwen-NEXT</h1>
<p><img src="assets/Qwen-QwenNext-Architecture.png" class="img-fluid"></p>



</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-PatchPackNaViT2023dehghani" class="csl-entry" role="listitem">
Dehghani, Mostafa, Basil Mustafa, Josip Djolonga, Jonathan Heek, Matthias Minderer, Mathilde Caron, Andreas Steiner, et al. 2023. <span>“Patch n’ <span>Pack</span>: <span>NaViT</span>, a <span>Vision Transformer</span> for Any <span>Aspect Ratio</span> and <span>Resolution</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2307.06304">https://doi.org/10.48550/arXiv.2307.06304</a>.
</div>
<div id="ref-ImageWorth16x162021dosovitskiy" class="csl-entry" role="listitem">
Dosovitskiy, Alexey, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, et al. 2021. <span>“An <span>Image</span> Is <span>Worth</span> 16x16 <span>Words</span>: <span>Transformers</span> for <span>Image Recognition</span> at <span>Scale</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2010.11929">https://doi.org/10.48550/arXiv.2010.11929</a>.
</div>
<div id="ref-RoFormerEnhancedTransformer2023su" class="csl-entry" role="listitem">
Su, Jianlin, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. 2023. <span>“<span>RoFormer</span>: <span>Enhanced Transformer</span> with <span>Rotary Position Embedding</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2104.09864">https://doi.org/10.48550/arXiv.2104.09864</a>.
</div>
<div id="ref-AttentionAllYou2023vaswani" class="csl-entry" role="listitem">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2023. <span>“Attention <span>Is All You Need</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1706.03762">https://doi.org/10.48550/arXiv.1706.03762</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© CC-By Yuyang, 2025</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This page is built with ❤️ and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




<script src="../../../../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.js" defer="true"></script>
</body></html>