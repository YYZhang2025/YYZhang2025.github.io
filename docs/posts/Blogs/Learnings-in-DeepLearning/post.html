<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yuyang Zhang">
<meta name="dcterms.date" content="2025-12-02">
<meta name="description" content="In the blog, I will cover all kind of learnings in Deep Learning, including supervised learning, unsupervised learning, self-supervised learning, reinforcement learning, and more. By the end, you will have a solid understanding of different learning paradigms in Deep Learning.">

<title>All kinds of “Learnings” in Deep Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../.././style/icon.avif" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-0348920b7671f696dc9078d39bff215e.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-859f99caab0bec132077bcc433b53446.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-970c7fc97ae78f6c1e7458e7c69915e7.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../site_libs/bootstrap/bootstrap-859f99caab0bec132077bcc433b53446.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="https://fonts.cdnfonts.com/css/cmu-sans-serif" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../style/styles.css">
<link rel="stylesheet" href="../../../style/callout.css">
<meta property="og:title" content="All kinds of “Learnings” in Deep Learning">
<meta property="og:description" content="In the blog, I will cover all kind of learnings in Deep Learning, including supervised learning, unsupervised learning, self-supervised learning, reinforcement learning, and more. By the end, you will have a solid understanding of different learning paradigms in Deep Learning.">
<meta property="og:image" content="./assets/Contrastive-Learning-Paragdim.png">
</head>

<body class="nav-sidebar docked nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/YYZhang2025"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/zhang-yuyang/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../posts/Blogs/blogs_index.html"> 
<span class="menu-text">Blogs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../posts/Projects/projects_index.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../posts/PapersWithCode/100_Papers_index.html"> 
<span class="menu-text">100 Papers with Code</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-learning-notes" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Learning Notes</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-learning-notes">    
        <li>
    <a class="dropdown-item" href="../../../posts/LearningNotes/CS336/index.html">
 <span class="dropdown-text">Stanford CS336: LLM from Scratch</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../posts/LearningNotes/DLFaC/index.html">
 <span class="dropdown-text">DLFaC</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../posts/LearningNotes/LLM-Series/index.html">
 <span class="dropdown-text">LLM Model Series</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title">All kinds of “Learnings” in Deep Learning</h1>
        </a>     
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="1">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#supervised-learning" id="toc-supervised-learning" class="nav-link active" data-scroll-target="#supervised-learning"><span class="header-section-number">1</span> Supervised Learning</a>
  <ul>
  <li><a href="#regression-problems" id="toc-regression-problems" class="nav-link" data-scroll-target="#regression-problems"><span class="header-section-number">1.1</span> Regression Problems</a></li>
  <li><a href="#classification-problems" id="toc-classification-problems" class="nav-link" data-scroll-target="#classification-problems"><span class="header-section-number">1.2</span> Classification Problems</a></li>
  </ul></li>
  <li><a href="#unsupervised-learning" id="toc-unsupervised-learning" class="nav-link" data-scroll-target="#unsupervised-learning"><span class="header-section-number">2</span> Unsupervised Learning</a>
  <ul>
  <li><a href="#clustering" id="toc-clustering" class="nav-link" data-scroll-target="#clustering"><span class="header-section-number">2.1</span> Clustering</a></li>
  <li><a href="#generative-models" id="toc-generative-models" class="nav-link" data-scroll-target="#generative-models"><span class="header-section-number">2.2</span> Generative Models</a>
  <ul>
  <li><a href="#variational-autoencoders-vae" id="toc-variational-autoencoders-vae" class="nav-link" data-scroll-target="#variational-autoencoders-vae"><span class="header-section-number">2.2.1</span> Variational Autoencoders (VAE)</a></li>
  <li><a href="#generative-adversarial-networks-gans" id="toc-generative-adversarial-networks-gans" class="nav-link" data-scroll-target="#generative-adversarial-networks-gans"><span class="header-section-number">2.2.2</span> Generative Adversarial Networks (GANs)</a></li>
  <li><a href="#normalizing-flows" id="toc-normalizing-flows" class="nav-link" data-scroll-target="#normalizing-flows"><span class="header-section-number">2.2.3</span> Normalizing Flows</a></li>
  <li><a href="#energy-based-models" id="toc-energy-based-models" class="nav-link" data-scroll-target="#energy-based-models"><span class="header-section-number">2.2.4</span> Energy-Based Models</a></li>
  <li><a href="#diffusion-models" id="toc-diffusion-models" class="nav-link" data-scroll-target="#diffusion-models"><span class="header-section-number">2.2.5</span> Diffusion Models</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#self-supervised-learning" id="toc-self-supervised-learning" class="nav-link" data-scroll-target="#self-supervised-learning"><span class="header-section-number">3</span> Self-Supervised Learning</a>
  <ul>
  <li><a href="#contrastive-learning" id="toc-contrastive-learning" class="nav-link" data-scroll-target="#contrastive-learning"><span class="header-section-number">3.1</span> Contrastive Learning</a></li>
  <li><a href="#masked-language-modeling-mlm" id="toc-masked-language-modeling-mlm" class="nav-link" data-scroll-target="#masked-language-modeling-mlm"><span class="header-section-number">3.2</span> Masked Language Modeling (MLM)</a></li>
  <li><a href="#autoregressive-modeling" id="toc-autoregressive-modeling" class="nav-link" data-scroll-target="#autoregressive-modeling"><span class="header-section-number">3.3</span> AutoRegressive Modeling</a></li>
  </ul></li>
  <li><a href="#semi-supervised-learning" id="toc-semi-supervised-learning" class="nav-link" data-scroll-target="#semi-supervised-learning"><span class="header-section-number">4</span> Semi-Supervised Learning</a></li>
  <li><a href="#deep-reinforcement-learning" id="toc-deep-reinforcement-learning" class="nav-link" data-scroll-target="#deep-reinforcement-learning"><span class="header-section-number">5</span> Deep Reinforcement Learning</a></li>
  <li><a href="#representation-learning" id="toc-representation-learning" class="nav-link" data-scroll-target="#representation-learning"><span class="header-section-number">6</span> Representation Learning</a></li>
  <li><a href="#transfer-learning" id="toc-transfer-learning" class="nav-link" data-scroll-target="#transfer-learning"><span class="header-section-number">7</span> Transfer Learning</a></li>
  <li><a href="#multi-task-learning" id="toc-multi-task-learning" class="nav-link" data-scroll-target="#multi-task-learning"><span class="header-section-number">8</span> Multi-Task Learning</a></li>
  <li><a href="#meta-learning" id="toc-meta-learning" class="nav-link" data-scroll-target="#meta-learning"><span class="header-section-number">9</span> Meta Learning</a></li>
  <li><a href="#online-learning" id="toc-online-learning" class="nav-link" data-scroll-target="#online-learning"><span class="header-section-number">10</span> Online Learning</a></li>
  <li><a href="#federated-learning" id="toc-federated-learning" class="nav-link" data-scroll-target="#federated-learning"><span class="header-section-number">11</span> Federated Learning</a></li>
  <li><a href="#curriculum-learning" id="toc-curriculum-learning" class="nav-link" data-scroll-target="#curriculum-learning"><span class="header-section-number">12</span> Curriculum Learning</a></li>
  <li><a href="#active-learning" id="toc-active-learning" class="nav-link" data-scroll-target="#active-learning"><span class="header-section-number">13</span> Active Learning</a></li>
  <li><a href="#zero-shot-and-few-shot-learning" id="toc-zero-shot-and-few-shot-learning" class="nav-link" data-scroll-target="#zero-shot-and-few-shot-learning"><span class="header-section-number">14</span> Zero-Shot and Few-Shot Learning</a></li>
  <li><a href="#continual-learning-lifelong-learning" id="toc-continual-learning-lifelong-learning" class="nav-link" data-scroll-target="#continual-learning-lifelong-learning"><span class="header-section-number">15</span> Continual Learning / Lifelong Learning</a></li>
  <li><a href="#manifold-learning" id="toc-manifold-learning" class="nav-link" data-scroll-target="#manifold-learning"><span class="header-section-number">16</span> Manifold Learning</a>
  <ul>
  <li><a href="#jepa" id="toc-jepa" class="nav-link" data-scroll-target="#jepa"><span class="header-section-number">16.1</span> JEPA</a></li>
  </ul></li>
  <li><a href="#nested-learning" id="toc-nested-learning" class="nav-link" data-scroll-target="#nested-learning"><span class="header-section-number">17</span> Nested Learning</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">18</span> Summary</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">All kinds of “Learnings” in Deep Learning</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Deep Learning</div>
    <div class="quarto-category">Summary</div>
  </div>
  </div>

<div>
  <div class="description">
    In the blog, I will cover all kind of learnings in Deep Learning, including supervised learning, unsupervised learning, self-supervised learning, reinforcement learning, and more. By the end, you will have a solid understanding of different learning paradigms in Deep Learning.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Yuyang Zhang </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">2025-12-02</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Last modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">2025-12-02</p>
    </div>
  </div>
    
  </div>
  


</header>

<nav id="TOC-body" role="doc-toc">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#supervised-learning" id="toc-supervised-learning"><span class="header-section-number">1</span> Supervised Learning</a>
  <ul>
  <li><a href="#regression-problems" id="toc-regression-problems"><span class="header-section-number">1.1</span> Regression Problems</a></li>
  <li><a href="#classification-problems" id="toc-classification-problems"><span class="header-section-number">1.2</span> Classification Problems</a></li>
  </ul></li>
  <li><a href="#unsupervised-learning" id="toc-unsupervised-learning"><span class="header-section-number">2</span> Unsupervised Learning</a>
  <ul>
  <li><a href="#clustering" id="toc-clustering"><span class="header-section-number">2.1</span> Clustering</a></li>
  <li><a href="#generative-models" id="toc-generative-models"><span class="header-section-number">2.2</span> Generative Models</a>
  <ul>
  <li><a href="#variational-autoencoders-vae" id="toc-variational-autoencoders-vae"><span class="header-section-number">2.2.1</span> Variational Autoencoders (VAE)</a></li>
  <li><a href="#generative-adversarial-networks-gans" id="toc-generative-adversarial-networks-gans"><span class="header-section-number">2.2.2</span> Generative Adversarial Networks (GANs)</a></li>
  <li><a href="#normalizing-flows" id="toc-normalizing-flows"><span class="header-section-number">2.2.3</span> Normalizing Flows</a></li>
  <li><a href="#energy-based-models" id="toc-energy-based-models"><span class="header-section-number">2.2.4</span> Energy-Based Models</a></li>
  <li><a href="#diffusion-models" id="toc-diffusion-models"><span class="header-section-number">2.2.5</span> Diffusion Models</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#self-supervised-learning" id="toc-self-supervised-learning"><span class="header-section-number">3</span> Self-Supervised Learning</a>
  <ul>
  <li><a href="#contrastive-learning" id="toc-contrastive-learning"><span class="header-section-number">3.1</span> Contrastive Learning</a></li>
  <li><a href="#masked-language-modeling-mlm" id="toc-masked-language-modeling-mlm"><span class="header-section-number">3.2</span> Masked Language Modeling (MLM)</a></li>
  <li><a href="#autoregressive-modeling" id="toc-autoregressive-modeling"><span class="header-section-number">3.3</span> AutoRegressive Modeling</a></li>
  </ul></li>
  <li><a href="#semi-supervised-learning" id="toc-semi-supervised-learning"><span class="header-section-number">4</span> Semi-Supervised Learning</a></li>
  <li><a href="#deep-reinforcement-learning" id="toc-deep-reinforcement-learning"><span class="header-section-number">5</span> Deep Reinforcement Learning</a></li>
  <li><a href="#representation-learning" id="toc-representation-learning"><span class="header-section-number">6</span> Representation Learning</a></li>
  <li><a href="#transfer-learning" id="toc-transfer-learning"><span class="header-section-number">7</span> Transfer Learning</a></li>
  <li><a href="#multi-task-learning" id="toc-multi-task-learning"><span class="header-section-number">8</span> Multi-Task Learning</a></li>
  <li><a href="#meta-learning" id="toc-meta-learning"><span class="header-section-number">9</span> Meta Learning</a></li>
  <li><a href="#online-learning" id="toc-online-learning"><span class="header-section-number">10</span> Online Learning</a></li>
  <li><a href="#federated-learning" id="toc-federated-learning"><span class="header-section-number">11</span> Federated Learning</a></li>
  <li><a href="#curriculum-learning" id="toc-curriculum-learning"><span class="header-section-number">12</span> Curriculum Learning</a></li>
  <li><a href="#active-learning" id="toc-active-learning"><span class="header-section-number">13</span> Active Learning</a></li>
  <li><a href="#zero-shot-and-few-shot-learning" id="toc-zero-shot-and-few-shot-learning"><span class="header-section-number">14</span> Zero-Shot and Few-Shot Learning</a></li>
  <li><a href="#continual-learning-lifelong-learning" id="toc-continual-learning-lifelong-learning"><span class="header-section-number">15</span> Continual Learning / Lifelong Learning</a></li>
  <li><a href="#manifold-learning" id="toc-manifold-learning"><span class="header-section-number">16</span> Manifold Learning</a>
  <ul>
  <li><a href="#jepa" id="toc-jepa"><span class="header-section-number">16.1</span> JEPA</a></li>
  </ul></li>
  <li><a href="#nested-learning" id="toc-nested-learning"><span class="header-section-number">17</span> Nested Learning</a></li>
  <li><a href="#summary" id="toc-summary"><span class="header-section-number">18</span> Summary</a></li>
  </ul>
</nav>
<p>In the AI field, Deep Learning, which is a subset of machine learning, has revolutionized the way we approach complex problems. One of the key aspects of Deep Learning is the various “learnings” or learning paradigms that <u>enable models to acquire knowledge from data</u>. In this blog, I will cover all kinds of learnings in Deep Learning, including supervised learning, unsupervised learning, self-supervised learning, reinforcement learning, and more. By the end, you will have a solid understanding of different learning paradigms in Deep Learning.</p>
<section id="supervised-learning" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Supervised Learning</h1>
<p>The most common and widely used learning paradigm in Deep Learning is <strong>Supervised Learning</strong>. In supervised learning, the model is trained on a labeled dataset, where each input data point is paired with its corresponding output label. The goal of the model is to learn a mapping from inputs to outputs, allowing it to make accurate predictions on unseen data. Mathematically, supervised learning can be formulated as follows: Given a dataset <span class="math inline">\(\mathcal{D}= \{(x_i, y_i)\}_{i=1}^{N}\)</span>, where <span class="math inline">\(x_i \in \mathbb{R}^d\)</span> represents the input data and <span class="math inline">\(y_i\)</span> represents the corresponding output value, the objective is to learn a function <span class="math inline">\(f: X \rightarrow Y\)</span> such that <span class="math inline">\(f(x_i) \approx y_i\)</span> for all <span class="math inline">\(i\)</span>.</p>
<section id="regression-problems" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="regression-problems"><span class="header-section-number">1.1</span> Regression Problems</h2>
<p>When the output variable is continuous, the task is referred to as a <strong>regression problem</strong>. Common examples of regression problems include predicting house prices, stock prices, or temperature values. Popular loss functions used in regression tasks include Mean Squared Error (MSE) and Mean Absolute Error (MAE).</p>
<p>Mean Squared Error (MSE): <span id="eq-loss-mse"><span class="math display">\[
\mathcal{L}_\text{MSE} = \frac{1}{N} \sum_{i=1}^{N} (y_i - f(x_i))^2
\tag{1}\]</span></span></p>
<p>Mean Absolute Error (MAE): <span id="eq-loss-mae"><span class="math display">\[
\mathcal{L}_\text{MAE} = \frac{1}{N} \sum_{i=1}^{N} |y_i - f(x_i)|
\tag{2}\]</span></span></p>
</section>
<section id="classification-problems" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="classification-problems"><span class="header-section-number">1.2</span> Classification Problems</h2>
<p>When the output variable is categorical, the task is referred to as a <strong>classification problem</strong>. Common examples of classification problems include image classification, spam detection, and sentiment analysis. Popular loss functions used in classification tasks include Cross-Entropy Loss and Hinge Loss.</p>
<p>Cross-Entropy Loss: <span id="eq-loss-ce"><span class="math display">\[
\mathcal{L}_\text{CE} = - \frac{1}{N} \sum_{i=1}^{N} \sum_{c=1}^{C} y_{i,c} \log(f_c(x_i))
\tag{3}\]</span></span> Hinge Loss: <span id="eq-loss-hinge"><span class="math display">\[
\mathcal{L}_\text{Hinge} = \frac{1}{N} \sum_{i=1}^{N} \max(0, 1 - y_i f(x_i))
\tag{4}\]</span></span></p>
</section>
</section>
<section id="unsupervised-learning" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Unsupervised Learning</h1>
<p>Unlike supervised learning, <strong>Unsupervised Learning</strong> involves training models on unlabeled data, where the goal is to discover patterns, structures, or relationships within the data without any explicit guidance. Unsupervised learning is particularly useful for tasks such as clustering, dimensionality reduction, and generative modeling. What we have is a dataset <span class="math inline">\(\mathcal{D}= \{x_i\}_{i=1}^{N}\)</span>, where <span class="math inline">\(x_i \in \mathbb{R}^d\)</span> represents the input data. The objective is to learn the underlying structure or distribution of the data. It can be broadly categorized into the following subfields:</p>
<ul>
<li>Clustering</li>
<li>Dimensionality Reduction</li>
<li>Generative Models</li>
</ul>
<section id="clustering" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="clustering"><span class="header-section-number">2.1</span> Clustering</h2>
<p>Clustering is the task of grouping similar data points together based on their features or characteristics. Common clustering algorithms include K-Means, Hierarchical Clustering, and DBSCAN.</p>
</section>
<section id="generative-models" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="generative-models"><span class="header-section-number">2.2</span> Generative Models</h2>
<p>Generative models aim to learn the underlying distribution of the data and generate new samples that resemble the original data. Some popular generative models include:</p>
<ul>
<li>Variational Autoencoders (VAE)</li>
<li>Generative Adversarial Networks (GANs)</li>
<li>Normalizing Flows</li>
<li>Energy-Based Models</li>
<li>Diffusion Models</li>
</ul>
<section id="variational-autoencoders-vae" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="variational-autoencoders-vae"><span class="header-section-number">2.2.1</span> Variational Autoencoders (VAE)</h3>
<p>The <strong>Variational Autoencoder (VAE)</strong> is a generative model that combines principles from variational inference and autoencoders. It consists of an encoder network that maps input data to a latent space and a decoder network that reconstructs the data from the latent representation. The VAE is trained to maximize the evidence lower bound (ELBO) on the data likelihood, which encourages the model to learn a meaningful latent representation while also generating realistic samples. The loss function for VAE can be expressed as:</p>
<p><span id="eq-loss-vae"><span class="math display">\[
\mathcal{L}_\text{VAE} = \mathbb{E}_{
q_\phi(z|x)}[\log p_\theta(x|z)] - D_{KL}(q_\phi(z|x) || p(z))
\tag{5}\]</span></span></p>
</section>
<section id="generative-adversarial-networks-gans" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="generative-adversarial-networks-gans"><span class="header-section-number">2.2.2</span> Generative Adversarial Networks (GANs)</h3>
<p><strong>Generative Adversarial Networks (GANs)</strong> are a class of generative models that consist of two neural networks: a generator and a discriminator. The generator aims to produce realistic samples that resemble the training data, while the discriminator tries to distinguish between real and generated samples. The two networks are trained in a minimax game, where the generator tries to fool the discriminator, and the discriminator tries to correctly classify real and fake samples. The objective function for GANs can be expressed as:</p>
<p><span id="eq-loss-gan"><span class="math display">\[
\min_G \max_D \mathbb{E}_{x \sim p_\text{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
\tag{6}\]</span></span></p>
</section>
<section id="normalizing-flows" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="normalizing-flows"><span class="header-section-number">2.2.3</span> Normalizing Flows</h3>
<p><strong>Normalizing Flows</strong> are a class of generative models that transform a simple probability distribution (e.g., Gaussian) into a more complex distribution by applying a series of invertible and differentiable transformations. The key idea is to use the change of variables formula to compute the likelihood of the data under the transformed distribution. Normalizing flows are trained by maximizing the log-likelihood of the data, which can be expressed as:</p>
<p><span id="eq-loss-nf"><span class="math display">\[
\log p_X(x) = \log p_Z(f^{-1}(x)) + \log \left| \det \frac{\partial f^{-1}(x)}{\partial x} \right|
\tag{7}\]</span></span></p>
</section>
<section id="energy-based-models" class="level3" data-number="2.2.4">
<h3 data-number="2.2.4" class="anchored" data-anchor-id="energy-based-models"><span class="header-section-number">2.2.4</span> Energy-Based Models</h3>
<p><strong>Energy-Based Models (EBMs)</strong> are a class of generative models that define a probability distribution over the data using an energy function. The energy function assigns low energy values to data points that are likely to occur and high energy values to unlikely data points. The probability distribution is defined as:</p>
<p><span id="eq-loss-ebm"><span class="math display">\[
p(x) = \frac{e^{-E(x)}}{Z}
\tag{8}\]</span></span> where <span class="math inline">\(E(x)\)</span> is the energy function and <span class="math inline">\(Z\)</span> is the partition function that normalizes the distribution. EBMs are trained by minimizing the energy of the training data while maximizing the energy of negative samples, which can be achieved using techniques such as Contrastive Divergence or Score Matching.</p>
</section>
<section id="diffusion-models" class="level3" data-number="2.2.5">
<h3 data-number="2.2.5" class="anchored" data-anchor-id="diffusion-models"><span class="header-section-number">2.2.5</span> Diffusion Models</h3>
<p><strong>Diffusion Models</strong> are a class of generative models that learn to generate data by reversing a diffusion process. The diffusion process gradually adds noise to the data, transforming it into a simple distribution (e.g., Gaussian). The model is trained to learn the reverse process, which denoises the data step by step, ultimately generating samples from the original data distribution. The training objective for diffusion models can be expressed as:</p>
<p><span id="eq-loss-diffusion"><span class="math display">\[
\mathcal{L}_\text{diffusion} = \mathbb{E}_{x_0, \epsilon, t} \left[ \| x_0 - f_\theta(x_t, t) \|^2 \right]
\tag{9}\]</span></span> where <span class="math inline">\(x_0\)</span> is the original data, <span class="math inline">\(x_t\)</span> is the noised data at time step <span class="math inline">\(t\)</span>, <span class="math inline">\(\epsilon\)</span> is the noise added, and <span class="math inline">\(f_\theta\)</span> is the denoising function parameterized by <span class="math inline">\(\theta\)</span>.</p>
</section>
</section>
</section>
<section id="self-supervised-learning" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Self-Supervised Learning</h1>
<p><strong>Self-Supervised Learning</strong> is a learning paradigm that leverages unlabeled data to create supervisory signals for training models. Create a pre-text task. In self-supervised learning, the model learns to predict certain aspects of the input data based on other parts of the data. This approach allows models to learn useful representations without the need for explicit labels. Common techniques in self-supervised learning include:</p>
<ul>
<li>Contrastive Learning</li>
<li>Masked Language Modeling (MLM)</li>
</ul>
<section id="contrastive-learning" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="contrastive-learning"><span class="header-section-number">3.1</span> Contrastive Learning</h2>
<div id="fig-contrastive-learning" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-contrastive-learning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/Contrastive-Learning-Paragdim.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-contrastive-learning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Illustration of Contrastive Learning
</figcaption>
</figure>
</div>
<p><strong>Contrastive Learning</strong> is a self-supervised learning technique that aims to learn representations by contrasting positive and negative pairs of data points. The model is trained to bring similar data points (positive pairs) closer together in the representation space while pushing dissimilar data points (negative pairs) apart. A popular loss function used in contrastive learning is the InfoNCE loss, which can be expressed as</p>
<p><span id="eq-loss-infonce"><span class="math display">\[
\mathcal{L}_\text{InfoNCE} = - \log \frac{\exp(\text{sim}(h_i, h_j) / \tau)}{\sum_{k=1}^{N} \exp(\text{sim}(h_i, h_k) / \tau)}
\tag{10}\]</span></span> where <span class="math inline">\(h_i\)</span> and <span class="math inline">\(h_j\)</span> are the representations of the positive pair, <span class="math inline">\(h_k\)</span> are the representations of negative samples, <span class="math inline">\(\text{sim}(\cdot, \cdot)\)</span> is a similarity function (e.g., cosine similarity), and <span class="math inline">\(\tau\)</span> is a temperature parameter.</p>
<p>One of the most popular frameworks for contrastive learning is SimCLR<span class="citation" data-cites="SimpleFrameworkContrastive2020chen">(<a href="#ref-SimpleFrameworkContrastive2020chen" role="doc-biblioref">Chen et al. 2020</a>)</span>, which uses data augmentations to create positive pairs and employs a deep neural network to learn representations.</p>
<p>The other one is DINO <span class="citation" data-cites="EmergingPropertiesSelfSupervised2021caron">(<a href="#ref-EmergingPropertiesSelfSupervised2021caron" role="doc-biblioref">Caron et al. 2021</a>)</span>, which leverages a teacher-student architecture to learn representations without the need for negative samples. <img src="./assets/dino-gif.gif" class="img-fluid quarto-figure quarto-figure-center"></p>
<p>The other contrastive learning methods is CLIP<span class="citation" data-cites="LearningTransferableVisual2021radford">(<a href="#ref-LearningTransferableVisual2021radford" role="doc-biblioref">Radford et al. 2021</a>)</span>, which learns joint representations of images and text by contrasting image-text pairs. CLIP has demonstrated impressive zero-shot learning capabilities across various vision tasks.</p>
<div id="fig-clip" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clip-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/clip.png" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clip-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: The illustration of CLIP model
</figcaption>
</figure>
</div>
</section>
<section id="masked-language-modeling-mlm" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="masked-language-modeling-mlm"><span class="header-section-number">3.2</span> Masked Language Modeling (MLM)</h2>
<p><strong>Masked Language Modeling (MLM)</strong> is a self-supervised learning technique commonly used in natural language processing (NLP). In MLM, a portion of the input tokens in a text sequence are randomly masked, and the model is trained to predict the original tokens based on the context provided by the unmasked tokens. This approach allows the model to learn contextual representations of words and phrases. The loss function for MLM can be expressed as:<br>
<span id="eq-loss-mlm"><span class="math display">\[
\mathcal{L}_\text{MLM} = - \sum_{i \in \mathcal{M}} \log p_\theta(x_i | x_{\setminus \mathcal{M}})
\tag{11}\]</span></span> where <span class="math inline">\(\mathcal{M}\)</span> is the set of masked token positions, <span class="math inline">\(x_i\)</span> is the original token at position <span class="math inline">\(i\)</span>, and <span class="math inline">\(x_{\setminus \mathcal{M}}\)</span> represents the input sequence with masked tokens.</p>
</section>
<section id="autoregressive-modeling" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="autoregressive-modeling"><span class="header-section-number">3.3</span> AutoRegressive Modeling</h2>
<p><strong>AutoRegressive Modeling</strong> is another self-supervised learning technique widely used in natural language processing . In autoregressive modeling, the model is trained to predict the next token in a sequence given the previous tokens. This approach allows the model to learn sequential dependencies and generate coherent text. The loss function for autoregressive modeling can be expressed as: <span id="eq-loss-ar"><span class="math display">\[
\mathcal{L}_\text{AR} = - \sum_{i=1}^{N} \log p_\theta(x_i | x_{&lt;i})
\tag{12}\]</span></span> where <span class="math inline">\(x_i\)</span> is the token at position <span class="math inline">\(i\)</span>, and <span class="math inline">\(x_{&lt;i}\)</span> represents the sequence of tokens preceding position <span class="math inline">\(i\)</span>.</p>
</section>
</section>
<section id="semi-supervised-learning" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Semi-Supervised Learning</h1>
<p><strong>Semi-Supervised Learning</strong> is a learning paradigm that combines both labeled and unlabeled data to improve model performance. In many real-world scenarios, obtaining labeled data can be expensive and time-consuming, while unlabeled data is often abundant. Semi-supervised learning leverages the information from unlabeled data to enhance the learning process. Common techniques in semi-supervised learning include: - Pseudo-Labeling - Consistency Regularization</p>
<p>To train a semi-supervised learning model, we have a labeled dataset <span class="math inline">\(\mathcal{D}_L = \{(x_i, y_i)\}_{i=1}^{N_L}\)</span> and an unlabeled dataset <span class="math inline">\(\mathcal{D}_U = \{x_j\}_{j=1}^{N_U}\)</span>. The objective is to learn a function <span class="math inline">\(f: X \rightarrow Y\)</span> that performs well on both labeled and unlabeled data. The overall loss function can be expressed as: <span id="eq-loss-ssl"><span class="math display">\[
\mathcal{L}_\text{SSL} = \mathcal{L}_\text{supervised} + \lambda \mathcal{L}_\text{unsupervised}
\tag{13}\]</span></span> where <span class="math inline">\(\mathcal{L}_\text{supervised}\)</span> is the loss computed on the labeled data, <span class="math inline">\(\mathcal{L}_\text{unsupervised}\)</span> is the loss computed on the unlabeled data, and <span class="math inline">\(\lambda\)</span> is a hyperparameter that balances the two loss components.</p>
</section>
<section id="deep-reinforcement-learning" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Deep Reinforcement Learning</h1>
<p><strong>Deep Reinforcement Learning (DRL)</strong> is a learning paradigm that combines reinforcement learning (RL) with deep learning techniques. In DRL, an agent learns to make decisions by interacting with an environment, receiving feedback in the form of rewards or penalties. The goal of the agent is to learn a policy that maximizes the cumulative reward over time. DRL has been successfully applied to various domains, including game playing, robotics, and autonomous systems.</p>
<p>There are several common algorithms in deep reinforcement learning, including: - Deep Q-Networks (DQN): Double DQN, Dueling DQN - Policy Gradient Methods: REINFORCE, Proximal Policy Optimization (PPO) - Actor-Critic Methods: A3C, DDPG</p>
</section>
<section id="representation-learning" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Representation Learning</h1>
<p><strong>Representation Learning</strong> is a learning paradigm that focuses on learning useful and informative representations of data. The goal of representation learning is to transform raw input data into a more meaningful and structured form that can be effectively used for downstream tasks such as classification, regression, or clustering. Representation learning can be achieved through various techniques, including: - Autoencoders - Principal Component Analysis (PCA) - t-Distributed Stochastic Neighbor Embedding (t-SNE)</p>
</section>
<section id="transfer-learning" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Transfer Learning</h1>
<p><strong>Transfer Learning</strong> is a learning paradigm that focuses on leveraging knowledge gained from one task or domain to improve performance on a different but related task or domain. The main idea behind transfer learning is that the features and representations learned by a model on a source task can be useful for solving a target task, especially when the target task has limited labeled data.</p>
</section>
<section id="multi-task-learning" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Multi-Task Learning</h1>
<p><strong>Multi-Task Learning (MTL)</strong> is a learning paradigm where a single model is trained to perform multiple related tasks simultaneously. The main idea behind MTL is that by sharing representations and knowledge across tasks, the model can learn more generalizable features that improve performance on each individual task. MTL can be particularly beneficial when the tasks are related and share commonalities, as it allows the model to leverage shared information and reduce overfitting.</p>
</section>
<section id="meta-learning" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Meta Learning</h1>
<p><strong>Meta Learning</strong>, also known as “learning to learn,” is a learning paradigm that focuses on training models to quickly adapt to new tasks or environments with minimal data. The main idea behind meta learning is to learn a meta-model that can generalize across a distribution of tasks, allowing it to efficiently learn new tasks by leveraging prior knowledge gained from previous tasks.</p>
</section>
<section id="online-learning" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Online Learning</h1>
<p><strong>Online Learning</strong> is a learning paradigm where the model learns incrementally from a stream of data, updating its parameters as new data points arrive. Unlike traditional batch learning, where the model is trained on a fixed dataset, online learning allows the model to adapt to changing data distributions and learn from new information in real-time. This approach is particularly useful in scenarios where data arrives continuously, such as in recommendation systems, financial markets, and sensor networks.</p>
</section>
<section id="federated-learning" class="level1" data-number="11">
<h1 data-number="11"><span class="header-section-number">11</span> Federated Learning</h1>
<p><strong>Federated Learning</strong> is a decentralized learning paradigm where multiple clients (e.g., devices or organizations) collaboratively train a shared model while keeping their local data private. In federated learning, each client trains the model on its local data and only shares model updates (e.g., gradients or weights) with a central server, which aggregates the updates to improve the global model. This approach allows for privacy-preserving learning, as sensitive data remains on the clients’ devices.</p>
</section>
<section id="curriculum-learning" class="level1" data-number="12">
<h1 data-number="12"><span class="header-section-number">12</span> Curriculum Learning</h1>
<p><strong>Curriculum Learning</strong> is a learning paradigm inspired by the way humans learn, where the model is trained on a sequence of tasks or examples that gradually increase in complexity. The main idea behind curriculum learning is to start with simpler tasks or examples and progressively introduce more difficult ones, allowing the model to build upon its existing knowledge and improve its performance over time. This approach can lead to faster convergence and better generalization, as the model learns to tackle complex problems in a structured manner.</p>
<div id="fig-curriculum-learning" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-curriculum-learning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./assets/curriculum-learning.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-curriculum-learning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: the illustration of Curriculum Learning
</figcaption>
</figure>
</div>
</section>
<section id="active-learning" class="level1" data-number="13">
<h1 data-number="13"><span class="header-section-number">13</span> Active Learning</h1>
<p>Active Learning is a learning paradigm where the model actively selects the most informative data points from a pool of unlabeled data to be labeled by an oracle (e.g., a human annotator). The main idea behind active learning is to prioritize labeling efforts on data points that are expected to provide the most significant improvement to the model’s performance. This approach can be particularly useful in scenarios where obtaining labeled data is expensive or time-consuming, as it allows for more efficient use of labeling resources.</p>
</section>
<section id="zero-shot-and-few-shot-learning" class="level1" data-number="14">
<h1 data-number="14"><span class="header-section-number">14</span> Zero-Shot and Few-Shot Learning</h1>
<p><strong>Zero-Shot Learning (ZSL)</strong> and <strong>Few-Shot Learning (FSL)</strong> are learning paradigms that focus on enabling models to generalize to new tasks or classes with little to no labeled data. In zero-shot learning, the model is expected to recognize and classify instances from classes it has never seen during training, typically by leveraging semantic information or attributes associated with the classes. In few-shot learning, the model is trained to quickly adapt to new classes with only a few labeled examples, often by utilizing meta-learning techniques or prior knowledge from related tasks.</p>
<p>This is the emergent area with the rise of large language models (LLMs) like GPT-3<span class="citation" data-cites="LanguageModelsAreradford">(<a href="#ref-LanguageModelsAreradford" role="doc-biblioref">Radford et al., n.d.</a>)</span>, which can perform various tasks with minimal or no task-specific training data.</p>
</section>
<section id="continual-learning-lifelong-learning" class="level1" data-number="15">
<h1 data-number="15"><span class="header-section-number">15</span> Continual Learning / Lifelong Learning</h1>
<p><strong>Continual Learning</strong> (also known as <strong>Lifelong Learning</strong>) is a learning paradigm where a model must learn from a sequence of tasks or data streams over time without forgetting what it learned before, while adapting to new information.</p>
<p>The main challenges in continual learning are:</p>
<ul>
<li><strong>Catastrophic Forgetting</strong>: When a model learns new tasks, it tends to forget previously learned tasks.</li>
<li><strong>Stability-Plasticity Dilemma</strong>: Balancing the need to retain old knowledge (stability) with the ability to learn new information (plasticity).</li>
<li><strong>Task Interference</strong>: Learning multiple tasks simultaneously can lead to interference between tasks, affecting performance.</li>
<li><strong>Resource Constraints</strong>: Continual learning models must often operate under limited computational and memory resources.</li>
</ul>
</section>
<section id="manifold-learning" class="level1" data-number="16">
<h1 data-number="16"><span class="header-section-number">16</span> Manifold Learning</h1>
<p>Manifold Learning is a learning paradigm that focuses on discovering the underlying low-dimensional structure (manifold) of high-dimensional data. The main idea behind manifold learning is that high-dimensional data often lies on or near a lower-dimensional manifold, and by learning this manifold, we can obtain more meaningful and compact representations of the data. Common techniques in manifold learning include: - Isomap - Locally Linear Embedding (LLE) - t-Distributed Stochastic Neighbor Embedding (t-SNE) - UMAP (Uniform Manifold Approximation and Projection)</p>
<section id="jepa" class="level2" data-number="16.1">
<h2 data-number="16.1" class="anchored" data-anchor-id="jepa"><span class="header-section-number">16.1</span> JEPA</h2>
<p><strong>Joint Embedding Predictive Architecture (JEPA)</strong> is a novel learning paradigm that focuses on learning joint embeddings of data from multiple modalities or views. The main idea behind JEPA is to learn a shared representation space where data points from different modalities can be compared and related to each other. This approach allows the model to capture the underlying structure and relationships between different types of data, enabling it to perform tasks such as cross-modal retrieval, multi-modal classification, and representation learning.</p>
</section>
</section>
<section id="nested-learning" class="level1" data-number="17">
<h1 data-number="17"><span class="header-section-number">17</span> Nested Learning</h1>
<p>Recently, Google Research proposed a new learning paradigm called <strong>Nested Learning</strong> <span class="citation" data-cites="NestedLearningIllusionbehrouz">(<a href="#ref-NestedLearningIllusionbehrouz" role="doc-biblioref">Behrouz et al., n.d.</a>)</span>, which aims to improve the efficiency and effectiveness of training deep learning models by organizing the learning process into nested levels. Each level focuses on different aspects of the data and model, allowing for a more structured and hierarchical approach to learning. This method has shown promising results in various applications, including natural language processing and computer vision.</p>
<p><img src="./assets/nested-learning-pardigm.png" class="img-fluid"></p>
</section>
<section id="summary" class="level1" data-number="18">
<h1 data-number="18"><span class="header-section-number">18</span> Summary</h1>
<p>Deep Learning based on Neural Networks can solve a wide range of complex problems by leveraging various learning paradigms. Each learning paradigm has its own strengths and weaknesses, and the choice of which one to use depends on the specific problem at hand, the available data, and the desired outcomes. By understanding these different learning paradigms, practitioners can make informed decisions about how to design and train their deep learning models for optimal performance.</p>



</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-NestedLearningIllusionbehrouz" class="csl-entry" role="listitem">
Behrouz, Ali, Meisam Razaviyayn, Peiling Zhong, and Vahab Mirrokni. n.d. <span>“Nested <span>Learning</span>: <span>The Illusion</span> of <span>Deep Learning Architectures</span>.”</span>
</div>
<div id="ref-EmergingPropertiesSelfSupervised2021caron" class="csl-entry" role="listitem">
Caron, Mathilde, Hugo Touvron, Ishan Misra, Hervé Jégou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. 2021. <span>“Emerging <span>Properties</span> in <span>Self-Supervised Vision Transformers</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2104.14294">https://doi.org/10.48550/arXiv.2104.14294</a>.
</div>
<div id="ref-SimpleFrameworkContrastive2020chen" class="csl-entry" role="listitem">
Chen, Ting, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. <span>“A <span>Simple Framework</span> for <span>Contrastive Learning</span> of <span>Visual Representations</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2002.05709">https://doi.org/10.48550/arXiv.2002.05709</a>.
</div>
<div id="ref-LearningTransferableVisual2021radford" class="csl-entry" role="listitem">
Radford, Alec, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, et al. 2021. <span>“Learning <span>Transferable Visual Models From Natural Language Supervision</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2103.00020">https://doi.org/10.48550/arXiv.2103.00020</a>.
</div>
<div id="ref-LanguageModelsAreradford" class="csl-entry" role="listitem">
Radford, Alec, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. n.d. <span>“Language <span>Models</span> Are <span>Unsupervised Multitask Learners</span>.”</span>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© CC-By Yuyang, 2025</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This page is built with ❤️ and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




<script src="../../../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.js" defer="true"></script>
</body></html>