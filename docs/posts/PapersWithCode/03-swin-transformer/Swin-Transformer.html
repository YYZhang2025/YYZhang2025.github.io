<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yuyang Zhang">
<meta name="description" content="Swin Transformer æ˜¯ä¸€ç§ä½¿ç”¨å±‚æ¬¡åŒ–ç»“æ„å’Œæ»‘åŠ¨çª—å£è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ViTæ¨¡å‹ï¼Œæ—¢ä¿ç•™äº†å±€éƒ¨å»ºæ¨¡çš„é«˜æ•ˆæ€§ï¼Œåˆé€šè¿‡çª—å£åç§»å®ç°è·¨åŒºåŸŸä¿¡æ¯äº¤äº’ï¼Œå¯ä½œä¸ºé€šç”¨è§†è§‰éª¨å¹²ç½‘ç»œï¼Œé€‚ç”¨äºå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ç­‰å¤šç§è§†è§‰ä»»åŠ¡ã€‚">

<title>03: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows(Swin Transformer)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../.././style/icon.avif" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-0348920b7671f696dc9078d39bff215e.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-6e97c76ec7d7e44d6e697e3c9997636d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-84bb4237d43bdfa05598834a807c2e5a.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../site_libs/bootstrap/bootstrap-6e97c76ec7d7e44d6e697e3c9997636d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="https://fonts.cdnfonts.com/css/cmu-sans-serif" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../style/styles.css">
<link rel="stylesheet" href="../../../style/callout.css">
<meta property="og:title" content="03: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows(Swin Transformer)">
<meta property="og:description" content="Swin Transformer æ˜¯ä¸€ç§ä½¿ç”¨å±‚æ¬¡åŒ–ç»“æ„å’Œæ»‘åŠ¨çª—å£è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ViTæ¨¡å‹ï¼Œæ—¢ä¿ç•™äº†å±€éƒ¨å»ºæ¨¡çš„é«˜æ•ˆæ€§ï¼Œåˆé€šè¿‡çª—å£åç§»å®ç°è·¨åŒºåŸŸä¿¡æ¯äº¤äº’ï¼Œå¯ä½œä¸ºé€šç”¨è§†è§‰éª¨å¹²ç½‘ç»œï¼Œé€‚ç”¨äºå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ç­‰å¤šç§è§†è§‰ä»»åŠ¡ã€‚">
<meta property="og:image" content="assets/swin-transformer-arch.jpg">
</head>

<body class="nav-sidebar docked nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/YYZhang2025"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/zhang-yuyang/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../posts/Blogs/blogs_index.html"> 
<span class="menu-text">Blogs</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-learning-notes" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Learning Notes</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-learning-notes">    
        <li>
    <a class="dropdown-item" href="../../.././posts/LearningNotes/DLFaC_index.qmd">
 <span class="dropdown-text">Deep Learning Foundations and Concepts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../.././posts/LearningNotes/CS336/CS336.qmd">
 <span class="dropdown-text">Stanford CS336: LLM from Scratch</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../posts/Projects/projects_index.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../posts/PapersWithCode/100_Papers_index.html"> 
<span class="menu-text">100 Papers with Code</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title">03: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows(<strong>Swin Transformer</strong>)</h1>
        </a>     
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="1">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#swin-transformer" id="toc-swin-transformer" class="nav-link active" data-scroll-target="#swin-transformer"><span class="header-section-number">1</span> Swin-Transformer</a>
  <ul>
  <li><a href="#window-multi-head-attention-w-mha" id="toc-window-multi-head-attention-w-mha" class="nav-link" data-scroll-target="#window-multi-head-attention-w-mha"><span class="header-section-number">1.1</span> Window Multi-Head-Attention (W-MHA)</a></li>
  <li><a href="#shifted-window-multi-head-attention-sw-mha" id="toc-shifted-window-multi-head-attention-sw-mha" class="nav-link" data-scroll-target="#shifted-window-multi-head-attention-sw-mha"><span class="header-section-number">1.2</span> Shifted Window Multi-Head-Attention (SW-MHA)</a></li>
  <li><a href="#consecutive-swin-transformer-block" id="toc-consecutive-swin-transformer-block" class="nav-link" data-scroll-target="#consecutive-swin-transformer-block"><span class="header-section-number">1.3</span> Consecutive Swin Transformer Block</a></li>
  <li><a href="#patch-merge" id="toc-patch-merge" class="nav-link" data-scroll-target="#patch-merge"><span class="header-section-number">1.4</span> Patch Merge</a></li>
  <li><a href="#relative-position-encoding" id="toc-relative-position-encoding" class="nav-link" data-scroll-target="#relative-position-encoding"><span class="header-section-number">1.5</span> Relative Position Encoding</a>
  <ul>
  <li><a href="#fine-tuning-in-different-image-size" id="toc-fine-tuning-in-different-image-size" class="nav-link" data-scroll-target="#fine-tuning-in-different-image-size"><span class="header-section-number">1.5.1</span> Fine-Tuning in different image size</a></li>
  </ul></li>
  <li><a href="#others" id="toc-others" class="nav-link" data-scroll-target="#others"><span class="header-section-number">1.6</span> Others</a></li>
  <li><a href="#downstream-tasks" id="toc-downstream-tasks" class="nav-link" data-scroll-target="#downstream-tasks"><span class="header-section-number">1.7</span> Downstream Tasks</a>
  <ul>
  <li><a href="#image-classification" id="toc-image-classification" class="nav-link" data-scroll-target="#image-classification"><span class="header-section-number">1.7.1</span> Image Classification</a></li>
  </ul></li>
  <li><a href="#object-detection-semantic-segmentation" id="toc-object-detection-semantic-segmentation" class="nav-link" data-scroll-target="#object-detection-semantic-segmentation"><span class="header-section-number">1.8</span> Object Detection &amp; Semantic segmentation</a></li>
  <li><a href="#training-details" id="toc-training-details" class="nav-link" data-scroll-target="#training-details"><span class="header-section-number">1.9</span> Training Details</a>
  <ul>
  <li><a href="#droppath" id="toc-droppath" class="nav-link" data-scroll-target="#droppath"><span class="header-section-number">1.9.1</span> DropPath</a></li>
  <li><a href="#gradient-checkpoint" id="toc-gradient-checkpoint" class="nav-link" data-scroll-target="#gradient-checkpoint"><span class="header-section-number">1.9.2</span> Gradient Checkpoint</a></li>
  </ul></li>
  <li><a href="#swin-v2" id="toc-swin-v2" class="nav-link" data-scroll-target="#swin-v2"><span class="header-section-number">1.10</span> Swin V2</a>
  <ul>
  <li><a href="#post-normalization" id="toc-post-normalization" class="nav-link" data-scroll-target="#post-normalization"><span class="header-section-number">1.10.1</span> Post normalization</a></li>
  <li><a href="#scaled-cosine-attention" id="toc-scaled-cosine-attention" class="nav-link" data-scroll-target="#scaled-cosine-attention"><span class="header-section-number">1.10.2</span> Scaled cosine attention</a></li>
  <li><a href="#log-spaced-continuous-position-biaslog-cpb" id="toc-log-spaced-continuous-position-biaslog-cpb" class="nav-link" data-scroll-target="#log-spaced-continuous-position-biaslog-cpb"><span class="header-section-number">1.10.3</span> Log-spaced Continuous Position Bias(Log-CPB)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">2</span> Summary</a></li>
  <li><a href="#key-concept-check-table" id="toc-key-concept-check-table" class="nav-link" data-scroll-target="#key-concept-check-table"><span class="header-section-number">3</span> Key Concept Check Table</a></li>
  <li><a href="#q-a" id="toc-q-a" class="nav-link" data-scroll-target="#q-a"><span class="header-section-number">4</span> Q &amp; A</a></li>
  <li><a href="#related-resource-further-reading" id="toc-related-resource-further-reading" class="nav-link" data-scroll-target="#related-resource-further-reading"><span class="header-section-number">5</span> Related resource &amp; Further Reading</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">03: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows(<strong>Swin Transformer</strong>)</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Computer-Vision</div>
  </div>
  </div>

<div>
  <div class="description">
    Swin Transformer æ˜¯ä¸€ç§ä½¿ç”¨å±‚æ¬¡åŒ–ç»“æ„å’Œæ»‘åŠ¨çª—å£è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ViTæ¨¡å‹ï¼Œæ—¢ä¿ç•™äº†å±€éƒ¨å»ºæ¨¡çš„é«˜æ•ˆæ€§ï¼Œåˆé€šè¿‡çª—å£åç§»å®ç°è·¨åŒºåŸŸä¿¡æ¯äº¤äº’ï¼Œå¯ä½œä¸ºé€šç”¨è§†è§‰éª¨å¹²ç½‘ç»œï¼Œé€‚ç”¨äºå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ç­‰å¤šç§è§†è§‰ä»»åŠ¡ã€‚
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Yuyang Zhang </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>

<nav id="TOC-body" role="doc-toc">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#swin-transformer" id="toc-swin-transformer"><span class="header-section-number">1</span> Swin-Transformer</a>
  <ul>
  <li><a href="#window-multi-head-attention-w-mha" id="toc-window-multi-head-attention-w-mha"><span class="header-section-number">1.1</span> Window Multi-Head-Attention (W-MHA)</a></li>
  <li><a href="#shifted-window-multi-head-attention-sw-mha" id="toc-shifted-window-multi-head-attention-sw-mha"><span class="header-section-number">1.2</span> Shifted Window Multi-Head-Attention (SW-MHA)</a></li>
  <li><a href="#consecutive-swin-transformer-block" id="toc-consecutive-swin-transformer-block"><span class="header-section-number">1.3</span> Consecutive Swin Transformer Block</a></li>
  <li><a href="#patch-merge" id="toc-patch-merge"><span class="header-section-number">1.4</span> Patch Merge</a></li>
  <li><a href="#relative-position-encoding" id="toc-relative-position-encoding"><span class="header-section-number">1.5</span> Relative Position Encoding</a>
  <ul>
  <li><a href="#fine-tuning-in-different-image-size" id="toc-fine-tuning-in-different-image-size"><span class="header-section-number">1.5.1</span> Fine-Tuning in different image size</a></li>
  </ul></li>
  <li><a href="#others" id="toc-others"><span class="header-section-number">1.6</span> Others</a></li>
  <li><a href="#downstream-tasks" id="toc-downstream-tasks"><span class="header-section-number">1.7</span> Downstream Tasks</a>
  <ul>
  <li><a href="#image-classification" id="toc-image-classification"><span class="header-section-number">1.7.1</span> Image Classification</a></li>
  </ul></li>
  <li><a href="#object-detection-semantic-segmentation" id="toc-object-detection-semantic-segmentation"><span class="header-section-number">1.8</span> Object Detection &amp; Semantic segmentation</a></li>
  <li><a href="#training-details" id="toc-training-details"><span class="header-section-number">1.9</span> Training Details</a>
  <ul>
  <li><a href="#droppath" id="toc-droppath"><span class="header-section-number">1.9.1</span> DropPath</a></li>
  <li><a href="#gradient-checkpoint" id="toc-gradient-checkpoint"><span class="header-section-number">1.9.2</span> Gradient Checkpoint</a></li>
  </ul></li>
  <li><a href="#swin-v2" id="toc-swin-v2"><span class="header-section-number">1.10</span> Swin V2</a>
  <ul>
  <li><a href="#post-normalization" id="toc-post-normalization"><span class="header-section-number">1.10.1</span> Post normalization</a></li>
  <li><a href="#scaled-cosine-attention" id="toc-scaled-cosine-attention"><span class="header-section-number">1.10.2</span> Scaled cosine attention</a></li>
  <li><a href="#log-spaced-continuous-position-biaslog-cpb" id="toc-log-spaced-continuous-position-biaslog-cpb"><span class="header-section-number">1.10.3</span> Log-spaced Continuous Position Bias(Log-CPB)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary"><span class="header-section-number">2</span> Summary</a></li>
  <li><a href="#key-concept-check-table" id="toc-key-concept-check-table"><span class="header-section-number">3</span> Key Concept Check Table</a></li>
  <li><a href="#q-a" id="toc-q-a"><span class="header-section-number">4</span> Q &amp; A</a></li>
  <li><a href="#related-resource-further-reading" id="toc-related-resource-further-reading"><span class="header-section-number">5</span> Related resource &amp; Further Reading</a></li>
  </ul>
</nav>
<section id="swin-transformer" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Swin-Transformer</h1>
<p>åœ¨é˜…è¯»Swin Transformer è¿™ç¯‡æ–‡ç« ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹ <a href="../../../posts/PapersWithCode/02-vision-transformer/Vision-Transformer.html">Vision-Transformer</a> è®²çš„æ˜¯ä»€ä¹ˆï¼š <u>ViT åœ¨å¤„ç†å›¾åƒæ—¶ï¼Œä¼šå°†æ•´å¼ å›¾åƒåˆ†å‰²æˆå›ºå®šå¤§å°çš„patchï¼Œå¹¶è¿›è¡Œglobal self-attentionçš„è®¡ç®—ï¼Œä»è€Œæ•æ‰å›¾åƒä¸­çš„å…¨å±€ä¿¡æ¯</u>ã€‚ ç„¶è€Œï¼Œ è¿™ç§æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªæ ¸å¿ƒçš„é—®é¢˜ï¼š</p>
<ol type="1">
<li><span style="color:rgb(255, 0, 0)">è®¡ç®—å¤æ‚åº¦é«˜</span>: ViTçš„è®¡ç®—å¤æ‚åº¦ä¸º <span class="math inline">\(\mathcal{O}(( \frac{HW}{P^2})^2)\)</span>ï¼Œå…¶ä¸­<span class="math inline">\(H\)</span>å’Œ<span class="math inline">\(W\)</span>åˆ†åˆ«æ˜¯å›¾åƒçš„é«˜åº¦å’Œå®½åº¦ï¼Œè€Œ<span class="math inline">\(P\)</span>æ˜¯patchçš„å¤§å°ã€‚å¯¹é«˜åˆ†è¾¨ç‡å›¾åƒï¼ˆHigh Resolution)ï¼ˆå¦‚æ£€æµ‹æˆ–åˆ†å‰²ä»»åŠ¡ï¼‰æ¥è¯´ï¼Œtoken æ•°é‡å·¨å¤§ï¼Œè®¡ç®—å’Œæ˜¾å­˜å¼€é”€éš¾ä»¥æ‰¿å—</li>
<li><span style="color:rgb(255, 0, 0)">ç¼ºä¹å±€éƒ¨ç‰¹å¾å»ºæ¨¡</span>: ViTåœ¨è¿›è¡Œ<strong>å…¨å±€è‡ªæ³¨æ„åŠ›</strong>è®¡ç®—æ—¶ï¼Œå¯èƒ½ä¼šå¿½ç•¥å›¾åƒä¸­çš„å±€éƒ¨ç‰¹å¾</li>
<li><span style="color:rgb(255, 0, 0)">æ²¡æœ‰é‡‘å­—å¡”å¼å±‚çº§ç»“æ„</span>: CNN çš„å±‚çº§ç»“æ„ï¼ˆä»ä½å±‚å±€éƒ¨ç‰¹å¾åˆ°é«˜å±‚è¯­ä¹‰ç‰¹å¾ï¼‰éå¸¸é€‚åˆå¤„ç†å¤šå°ºåº¦ç›®æ ‡, ViT ç›´æ¥ç”¨å›ºå®šå¤§å° patch flatten æˆåºåˆ—ï¼Œç¼ºä¹å±‚æ¬¡è¡¨ç¤ºï¼Œéš¾ä»¥é€‚åº”å¯†é›†é¢„æµ‹ä»»åŠ¡ï¼ˆå¦‚ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ï¼‰ã€‚</li>
</ol>
<blockquote class="blockquote">
<p>We observe that significant challenges in transferring its high performance in the language domain to the visual domain can be explained by differences between the two modalities. <u>One of these differences involves scale</u> â€¦ <u>visual elements can vary substantially in scale</u> â€¦ Another difference is the <u>much higher resolution of pixels in images</u> compared to words in passages of text â€¦ as the <u>computational complexity of its self-attention is quadratic to image size</u>. <cite> Swin Transformer Hierarchical Vision Transformer using Shifted Windows, p.&nbsp;</cite></p>
</blockquote>
<p>ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œ Swin Transformer <span class="citation" data-cites="SwinTransformerHierarchical2021liu">(<a href="#ref-SwinTransformerHierarchical2021liu" role="doc-biblioref">Liu, Lin, et al. 2021</a>)</span> æå‡ºä¸€ç§æ–°çš„åŸºäº Vision Transformerçš„æ¶æ„å®ƒé€šè¿‡å¼•å…¥<strong>å±‚æ¬¡åŒ–çš„ç‰¹å¾è¡¨ç¤º(Hierarchical Architecture)</strong> å’Œ <strong>ç§»åŠ¨çª—å£æœºåˆ¶(Shifted Window MSA, SW-MSA)</strong>ï¼Œæ¥æœ‰æ•ˆåœ°æ•æ‰å›¾åƒä¸­çš„å±€éƒ¨å’Œå…¨å±€ä¿¡æ¯ï¼Œ å¹¶ä¸”é€šè¿‡<strong>å±€éƒ¨çª—å£(Window-based Multi-head Self Attention, W-MSA)</strong> æ³¨æ„åŠ›ï¼Œæ¥é™ä½è®­ç»ƒçš„æ—¶é—´å¤æ‚åº¦ã€‚</p>
<p><img src="assets/swin-transformer-arch.jpg" class="img-fluid"></p>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥è¯¦ç»†ä»‹ç» Swin Transformer çš„æ¶æ„å’Œå…³é”®æŠ€æœ¯ã€‚æˆ‘ä»¬é¦–å…ˆæ¥çœ‹Swin Transformer çš„Attentionçš„å®ç°ã€‚</p>
<section id="window-multi-head-attention-w-mha" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="window-multi-head-attention-w-mha"><span class="header-section-number">1.1</span> Window Multi-Head-Attention (W-MHA)</h2>
<p>W-MHA çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š</p>
<ul>
<li>æŠŠå›¾åƒåˆ’åˆ†æˆå›ºå®šå¤§å°çš„çª—å£ï¼ˆwindowï¼‰ï¼Œæ¯”å¦‚ 7Ã—7 patch çš„çª—å£ã€‚</li>
<li>åœ¨çª—å£å†…çš„ token ä¹‹é—´åšå±€éƒ¨è‡ªæ³¨æ„åŠ›ï¼Œè€Œä¸æ˜¯åœ¨æ•´å¼ å›¾åƒçš„æ‰€æœ‰ token ä¹‹é—´åšå…¨å±€æ³¨æ„åŠ›ã€‚</li>
<li>æ¯ä¸ªçª—å£ç‹¬ç«‹è®¡ç®— Multi-Head Attention â†’ é™ä½è®¡ç®—é‡ï¼Œå¹¶ä¸”æˆ‘ä»¬å¯ä»¥å¹¶è¡Œçš„è®¡ç®—</li>
</ul>
<p>è¿™æ ·ä¸€æ¥ï¼š</p>
<ul>
<li>å•ä¸ªçª—å£ token æ•°é‡å›ºå®š = <span class="math inline">\(M^{2}\)</span>ï¼ˆå¦‚ 7Ã—7=49ï¼‰ã€‚</li>
<li>æ³¨æ„åŠ›è®¡ç®—å¤æ‚åº¦ä» <span class="math inline">\(\mathcal{O}((hw)^{2}C)\)</span> é™ä½ä¸º <span class="math inline">\(\mathcal{O}(M^{2}hwC)\)</span>ï¼Œå…¶ä¸­ <span class="math inline">\(M \ll \sqrt{ N }\)</span>ã€‚</li>
</ul>
<p>é™¤äº†é™ä½è®¡ç®—å¤æ‚åº¦ä¹‹å¤–ï¼ŒW-MHAï¼Œè¿˜æœ‰ä¿ç•™CNN åœ¨å›¾åƒå¤„ç†ä¸­å¼ºå¤§çš„ä¸€ç‚¹æ˜¯ å±€éƒ¨æ„Ÿå—é‡ å’Œ å¹³ç§»ä¸å˜æ€§ã€‚</p>
<ul>
<li>W-MHA é€šè¿‡çª—å£é™åˆ¶ï¼Œä½¿å¾—æ³¨æ„åŠ›æœºåˆ¶ä¹Ÿå…·å¤‡ç±»ä¼¼çš„å±€éƒ¨å½’çº³åç½®ï¼ˆinductive biasï¼‰ï¼Œé€‚åˆå›¾åƒå»ºæ¨¡ã€‚</li>
</ul>
<blockquote class="blockquote">
<p>For efficient modeling, we propose to compute self-attention within local windows. The windows are arranged to evenly partition the image in a non-overlapping manner. <cite> Swin Transformer Hierarchical Vision Transformer using Shifted Windows, p.4 </cite></p>
</blockquote>
</section>
<section id="shifted-window-multi-head-attention-sw-mha" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="shifted-window-multi-head-attention-sw-mha"><span class="header-section-number">1.2</span> Shifted Window Multi-Head-Attention (SW-MHA)</h2>
<p>W-MHA å¾ˆå¥½ï¼Œä½†æ˜¯å®ƒå­˜åœ¨çš„ä¸€ä¸ªé—®é¢˜å°±æ˜¯ï¼š</p>
<ul>
<li>çª—å£ä¹‹é—´æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼Œç¼ºå°‘è·¨çª—å£çš„ä¿¡æ¯äº¤æµã€‚è¿™ä¼šå¯¼è‡´ï¼Œæ¨¡å‹åªèƒ½çœ‹è§å±€éƒ¨ï¼Œä¸èƒ½è·å¾—å…¨å±€çš„ä¿¡æ¯ã€‚</li>
</ul>
<blockquote class="blockquote">
<p>The window-based self-attention module lacks connections across windows, which limits its modeling power. To introduce cross-window connections while maintaining the efficient computation of non-overlapping windows, we propose a shifted window partitioning approach which alternates between two partitioning configurations in consecutive Swin Transformer blocks. <cite> Swin Transformer Hierarchical Vision Transformer using Shifted Windows, p.4 </cite></p>
</blockquote>
<p>ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒSwin- Transformeræå‡ºæ¥ Shifted Window Mulit-Head-Attention (SW-MHA) çª—å£ä½ç½®ç›¸å¯¹å‰ä¸€å±‚å¹³ç§»ï¼Œæ¯”å¦‚ 7Ã—7 çª—å£ â†’ å¹³ç§» 3 ä¸ª patchã€‚ è¿™æ ·ï¼Œæ–°çš„çª—å£ä¼šè·¨è¶ŠåŸæ¥çš„è¾¹ç•Œï¼Œtoken ä¼šå’Œç›¸é‚»çª—å£çš„ token ä¸€èµ·è®¡ç®—æ³¨æ„åŠ›ã€‚ ç›¸å½“äºå¼ºåˆ¶è·¨çª—å£äº¤äº’ï¼Œè®©ä¿¡æ¯å¯ä»¥åœ¨ä¸åŒåŒºåŸŸä¹‹é—´æµåŠ¨ã€‚</p>
<p><img src="assets/Swin-Transformer-shift-window-padding.png" class="img-fluid"> å¦‚ä¸Šå¦‚æ‰€ç¤ºï¼Œæˆ‘ä»¬å°†Windowé€šè¿‡å‘å·¦ä¸Šè§’ç§»åŠ¨ï¼Œé€šè¿‡ç»™å›¾ç‰‡å¢åŠ Paddingæ¥ï¼Œä½†æ˜¯è¿™ç§åŠæ³•æ˜¾ç„¶ä¼šå¢åŠ è®¡ç®—çš„å¤æ‚åº¦ã€‚Swin Transformerç”¨äº†ä¸€ç§å¾ˆèªæ˜çš„åŠæ³•ï¼Œå«åš Cycling Shiftï¼Œè¿™ç§æ–¹æ³•å°±æ˜¯å°†å°†ä¸€ä¸ªå¼ é‡æˆ–å›¾åƒåœ¨æŸä¸ªç»´åº¦ä¸Šåš å¹³ç§»ï¼Œä½†ä¸æ˜¯æŠŠç§»å‡ºå»çš„éƒ¨åˆ†ä¸¢æ‰ï¼Œè€Œæ˜¯ é‡æ–°ä»å¦ä¸€è¾¹è¡¥å›æ¥ã€‚å°±åƒâ€œç¯å½¢é˜Ÿåˆ—â€æˆ–â€œé’Ÿè¡¨èµ°ä¸€åœˆåˆå›åˆ°èµ·ç‚¹â€ã€‚ å¦‚ä¸‹å›¾æ‰€ç¤º <img src="assets/Swin-Transformer-After-cyclic-shift.png" class="img-fluid"></p>
<p>å¯ä»¥çœ‹åˆ°ï¼Œé€šè¿‡Cycling Shiftï¼Œæˆ‘ä»¬å¾—åˆ°çš„æ¯ä¸ªwindowçš„å†…å®¹ï¼Œå’Œä¹‹å‰æ˜¯ä¸€æ ·çš„ï¼Œä½†æ˜¯æ‰€éœ€è¦çš„Windowçš„æ•°é‡ï¼Œå°äº†å¾ˆå¤šï¼Œè¿™ä¹Ÿå°±æ„å‘³ç€ï¼Œæ‰€éœ€è¦çš„æ—¶é—´å¤æ‚åº¦ï¼Œä¹Ÿå°äº†å¾ˆå¤šã€‚</p>
<p><img src="assets/swin-transformer-cyclic.png" class="img-fluid"></p>
<p>ä¸è¿‡Cycling Shiftä¹Ÿæœ‰ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åŒä¸€ä¸ªçª—å£é‡Œé¢ï¼Œå¯èƒ½æœ‰æ¥è‡ªä¸åŒå›¾ç‰‡çš„ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯åœ¨åŸå›¾ç‰‡ä¸Šä¸æ˜¯ç›¸é‚»çš„ï¼Œè‡ªç„¶ä¸åº”è¯¥ç›¸äº’äº¤æµä¿¡æ¯ã€‚æˆ‘ä»¬å¯ä»¥å°†å›¾ç‰‡ï¼ŒæŠ½è±¡æˆä¸‹å›¾çš„å½¢å¼ã€‚ç»„ç»‡Attentionäº¤æµï¼Œå¾ˆè‡ªç„¶çš„ä¸€ç§æ–¹æ³•æ˜¯åˆ©ç”¨Maskï¼Œå°±åƒ<a href="../../../posts/PapersWithCode/01-transformer/Transformer.html">Transformer</a>é‡Œçš„Causal Maskä¸€æ ·ã€‚ä½†æ˜¯ï¼Œè¿™ä¸ªMaské•¿ä»€ä¹ˆæ ·å­å‘¢</p>
<p><img src="assets/Swin-Transformer-shift-window-label.png" class="img-fluid"></p>
<p>æˆ‘ä»¬å¯ä»¥çœ‹ä¸€ä¸‹Maskï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæœ‰é¢œè‰²çš„åŒºåŸŸè¡¨ç¤ºMask == 1ï¼Œ åœ¨æ­¤ä¸ºäº†æ›´å¥½çš„</p>
<p><img src="assets/Swin-Transformer-shift-window-mask.png" class="img-fluid"></p>
</section>
<section id="consecutive-swin-transformer-block" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="consecutive-swin-transformer-block"><span class="header-section-number">1.3</span> Consecutive Swin Transformer Block</h2>
<blockquote class="blockquote">
<p>Swin Transformer is built by replacing the standard multi-head self attention (MSA) module in a Transformer block by a module based on shifted windows (described in Section 3.2), with other layers kept the same. As illustrated in Figure 3(b), a Swin Transformer block consists of a shifted window based MSA module, followed by a 2-layer MLP with GELU nonlinearity in between. A LayerNorm (LN) layer is applied before each MSA module and each MLP, and a residual connection is applied after each module <cite> Swin Transformer Hierarchical Vision Transformer using Shifted Windows, p.4 </cite></p>
</blockquote>
<p><img src="assets/Swin-Transformer-Layers.png" class="img-fluid"></p>
<p><span class="math display">\[
\begin{split}
\hat{z}^l &amp;= \text{W-MSA} \left( \text{LN} \left( z^{l-1} \right) \right) + z^{l-1} \\
z^l &amp;= \text{MLP} \left( \text{LN} \left( \hat{z}^l \right) \right) + \hat{z}^l \\
\hat{z}^{l+1} &amp;= \text{SW-MSA} \left( \text{LN} \left( z^l \right) \right) + z^l \\
z^{l+1} &amp;= \text{MLP} \left( \text{LN} \left( \hat{z}^{l+1} \right) \right) + \hat{z}^{l+1}
\end{split}
\]</span></p>
<p>å°†W-MSA å’Œ SW-MSAå åœ¨ä¸€èµ·ï¼Œå°±å¾—åˆ°äº†Transformer Blockï¼Œå½“ç„¶ï¼Œè¿˜æœ‰ä¸€ä¸ªMLPï¼ŒLayer Normalizationï¼Œåœ¨æ­¤å°±ä¸èµ˜è¿°äº†ã€‚</p>
</section>
<section id="patch-merge" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="patch-merge"><span class="header-section-number">1.4</span> Patch Merge</h2>
<p>è®²å®Œäº†W-MHAï¼Œå’ŒSW-MHAï¼Œæˆ‘ä»¬å°±ç†è§£äº†Swin- Transformerä¸­æœ€éš¾ç†è§£ï¼Œä¹Ÿæ˜¯æœ€ç»ˆçš„éƒ¨åˆ†ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬çœ‹çœ‹å…¶ä»–ç®€å•çš„éƒ¨åˆ†ã€‚ Patch Merge , å›¾ä¸­ç»¿è‰²çš„éƒ¨åˆ†ï¼Œé€æ­¥é™ä½ token æ•°é‡ï¼ˆé™é‡‡æ ·ï¼‰ï¼ŒåŒæ—¶å¢åŠ ç‰¹å¾ç»´åº¦çš„æ“ä½œã€‚è¿™ç±»ä¼¼äºCNNä¸­çš„æ“ä½œï¼Œéšç€å±‚æ•°çš„å¢åŠ ï¼Œåˆ†è¾¨ç‡é€æ­¥é™ä½ã€é€šé“æ•°é€æ­¥å¢åŠ ï¼Œè¿™æ ·æ—¢å‡å°‘äº†è®¡ç®—é‡ï¼Œåˆèƒ½æå–å±‚çº§ç‰¹å¾ã€‚å…·ä½“çš„å®ç°ï¼š</p>
<ol type="1">
<li>åˆ†ç»„ï¼šå°†ç›¸é‚»çš„ 2Ã—2 patch åˆå¹¶æˆä¸€ä¸ªæ–°çš„ patchã€‚
<ul>
<li>å‡è®¾è¾“å…¥ç‰¹å¾å¤§å°ä¸º (H, W, C)ã€‚</li>
<li>æ¯ 2Ã—2 çš„ patch â†’ åˆå¹¶ä¸º 1 ä¸ªæ–° tokenã€‚</li>
<li>æ–°ç‰¹å¾å›¾å¤§å°å˜ä¸º (H/2, W/2, 4C)ã€‚</li>
</ul></li>
<li>çº¿æ€§å˜æ¢:
<ul>
<li>å°†åˆå¹¶åçš„ 4C ç»´ç‰¹å¾é€šè¿‡ä¸€ä¸ª çº¿æ€§å±‚ (Linear Projection)ï¼Œé™åˆ° 2C ç»´ã€‚</li>
<li>è¾“å‡ºç»´åº¦ç¿»å€ï¼ˆ2Cï¼‰ï¼Œä»¥è¡¥å¿åˆ†è¾¨ç‡å‡åŠå¸¦æ¥çš„ä¿¡æ¯æŸå¤±ã€‚ ğŸ”¹ ä¸ºä»€ä¹ˆæå‡º Patch Merging</li>
</ul>
<ol type="1">
<li>åˆ†å±‚è¡¨ç¤º (Hierarchical Representation) â€¢ æ¨¡ä»¿ CNN çš„é‡‘å­—å¡”ç»“æ„ï¼Œä»å±€éƒ¨ç»†èŠ‚é€æ­¥èšåˆåˆ°å…¨å±€è¯­ä¹‰ã€‚ â€¢ æœ‰åˆ©äºä¸‹æ¸¸ä»»åŠ¡ï¼ˆæ£€æµ‹ã€åˆ†å‰²ï¼‰ä¸­ä¸åŒå°ºåº¦çš„ç›®æ ‡å»ºæ¨¡ã€‚</li>
<li>è®¡ç®—æ•ˆç‡ â€¢ token æ•°é‡é€å±‚å‡å°‘ â†’ Attention çš„å¤æ‚åº¦å¤§å¹…ä¸‹é™ã€‚ â€¢ ä¿è¯æ¨¡å‹å¯æ‰©å±•åˆ°å¤§åˆ†è¾¨ç‡å›¾åƒã€‚</li>
<li>è¯­ä¹‰ä¿¡æ¯èšåˆ â€¢ é€šè¿‡åˆå¹¶ç›¸é‚» patchï¼Œæ¨¡å‹èƒ½æŠŠæ›´å¤§æ„Ÿå—é‡çš„ä¿¡æ¯æ•´åˆåˆ°æ–°çš„ token ä¸­ã€‚</li>
</ol></li>
</ol>
<div class="sourceCode" id="cb1" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a>x <span class="op">=</span> x.view(B, H, W, C)</span>
<span id="cb1-2"><a href="#cb1-2"></a></span>
<span id="cb1-3"><a href="#cb1-3"></a>x0 <span class="op">=</span> x[:, <span class="dv">0</span>::<span class="dv">2</span>, <span class="dv">0</span>::<span class="dv">2</span>, :]  <span class="co"># (B, H/2, W/2, C)</span></span>
<span id="cb1-4"><a href="#cb1-4"></a>x1 <span class="op">=</span> x[:, <span class="dv">1</span>::<span class="dv">2</span>, <span class="dv">0</span>::<span class="dv">2</span>, :]  <span class="co"># (B, H/2, W/2, C)</span></span>
<span id="cb1-5"><a href="#cb1-5"></a>x2 <span class="op">=</span> x[:, <span class="dv">0</span>::<span class="dv">2</span>, <span class="dv">1</span>::<span class="dv">2</span>, :]  <span class="co"># (B, H/2, W/2, C)</span></span>
<span id="cb1-6"><a href="#cb1-6"></a>x3 <span class="op">=</span> x[:, <span class="dv">1</span>::<span class="dv">2</span>, <span class="dv">1</span>::<span class="dv">2</span>, :]  <span class="co"># (B, H/2, W/2, C)</span></span>
<span id="cb1-7"><a href="#cb1-7"></a></span>
<span id="cb1-8"><a href="#cb1-8"></a>x <span class="op">=</span> torch.cat([x0, x1, x2, x3], <span class="op">-</span><span class="dv">1</span>)  <span class="co"># (B, H/2, W/2, 4*C)</span></span>
<span id="cb1-9"><a href="#cb1-9"></a>x <span class="op">=</span> x.view(B, <span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span> <span class="op">*</span> C)  <span class="co"># (B, H/2*W/2, 4*C)</span></span>
<span id="cb1-10"><a href="#cb1-10"></a></span>
<span id="cb1-11"><a href="#cb1-11"></a>x <span class="op">=</span> <span class="va">self</span>.reduction(x)  <span class="co"># (B, H/2*W/2, 2*C)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="relative-position-encoding" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="relative-position-encoding"><span class="header-section-number">1.5</span> Relative Position Encoding</h2>
<p>ä¸<a href="../../../posts/PapersWithCode/01-transformer/Transformer.html">Transformer</a> å’Œ <a href="../../../posts/PapersWithCode/02-vision-transformer/Vision-Transformer.html">Vision-Transformer</a> ä¸­ä¸åŒçš„æ˜¯ï¼ŒSwin Transformeråˆ©ç”¨çš„æ˜¯Relative Position Encodingã€‚</p>
<p><span class="math display">\[
\text{Attention}(Q, K, V) = \text{Softmax}\left( \frac{QK^{T}}{\sqrt{ d }} +B\right) V
\]</span></p>
<pre data-code-line-numbers=""><code>1.  å®šä¹‰åç½®è¡¨ (relative_position_bias_table)
â€¢   å¤§å°æ˜¯ (2*Wh-1) * (2*Ww-1, num_heads)
â€¢   æ„å‘³ç€çª—å£å†…çš„ä»»æ„ä¸¤ä¸ª token çš„ç›¸å¯¹ä½ç½® (dx, dy)ï¼Œéƒ½æœ‰ä¸€ä¸ªå¯å­¦ä¹ çš„åç½®å€¼ï¼ˆæ¯ä¸ª head ä¸€ä»½ï¼‰ã€‚
â€¢   ä¾‹å¦‚çª—å£æ˜¯ 7Ã—7 â†’ ç›¸å¯¹ä½ç½®èŒƒå›´æ˜¯ [-6,6]ï¼Œæ‰€ä»¥è¡¨å¤§å°æ˜¯ 13Ã—13=169ï¼Œæ¯ä¸ªä½ç½®å­˜ä¸€ç»„åç½®


2.  è®¡ç®—ç›¸å¯¹ä½ç½®ç´¢å¼• (relative_position_index)
â€¢   é¦–å…ˆç”Ÿæˆçª—å£å†…æ¯ä¸ª token çš„åæ ‡ã€‚
â€¢   ç„¶ååšå·®ï¼Œå¾—åˆ°ä»»æ„ä¸¤ä¸ª token çš„ç›¸å¯¹åæ ‡ (dx, dy)ã€‚
â€¢   å†æ˜ å°„æˆè¡¨çš„ç´¢å¼•ï¼ˆé€šè¿‡ç§»ä½å’Œå“ˆå¸Œæˆä¸€ä¸ªæ•´æ•° indexï¼‰ã€‚
â€¢   ç»“æœæ˜¯ä¸€ä¸ª (Wh*Ww, Wh*Ww) çš„çŸ©é˜µï¼Œæ¯ä¸ªå…ƒç´ å­˜ä¸¤ä¸ª token ä¹‹é—´åœ¨ bias è¡¨é‡Œçš„ç´¢å¼•ã€‚


â€¢   åœ¨å›¾åƒé‡Œï¼Œç›¸å¯¹ä½ç½®æ¯”ç»å¯¹ä½ç½®æ›´é‡è¦ï¼š
â€¢   æ¯”å¦‚ä¸€ä¸ªåƒç´ çš„å·¦é‚»å’Œå³é‚»å¾ˆç›¸ä¼¼ï¼Œæ— è®ºè¿™ä¸ªåƒç´ åœ¨å›¾åƒçš„å“ªä¸ªåœ°æ–¹ã€‚</code></pre>
<p><span class="math display">\[
\begin{tabular}
\Xhline{1.0pt}
&amp; \multicolumn{2}{c|}{ImageNet} &amp; \multicolumn{2}{c|}{COCO} &amp; \multicolumn{1}{c}{ADE20k} \\
&amp; top-1 &amp; top-5  &amp; AP$^\text{box}$ &amp; AP$^\text{mask}$ &amp; mIoU \\
\hline
no pos. &amp; 80.1 &amp; 94.9 &amp; 49.2 &amp; 42.6  &amp; 43.8 \\
abs. pos. &amp; 80.5 &amp; 95.2 &amp; 49.0 &amp; 42.4  &amp; 43.2 \\
abs.+rel. pos. &amp; 81.3 &amp; 95.6 &amp; 50.2 &amp; 43.4 &amp; 44.0\\
rel. pos. w/o app. &amp; 79.3 &amp; 94.7 &amp; 48.2 &amp; 41.9 &amp; 44.1 \\
rel. pos. &amp; \textbf{81.3} &amp; \textbf{95.6} &amp; \textbf{50.5} &amp; \textbf{43.7} &amp; \textbf{46.1} \\
\Xhline{1.0pt}
\end{tabular}
\]</span></p>
<section id="fine-tuning-in-different-image-size" class="level3" data-number="1.5.1">
<h3 data-number="1.5.1" class="anchored" data-anchor-id="fine-tuning-in-different-image-size"><span class="header-section-number">1.5.1</span> Fine-Tuning in different image size</h3>
<p>å’Œ <a href="../../../posts/PapersWithCode/02-vision-transformer/Vision-Transformer.html">Vision-Transformer</a> ä¸€æ ·ï¼Œå½“è¾“å…¥çš„å›¾ç‰‡å’Œè®­ç»ƒæ—¶ä¸ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ <strong>bi-cubic interpolation</strong> æ¥å¢å¤§Relative Position</p>
<blockquote class="blockquote">
<p>The learnt relative position bias in pre-training can be also used to initialize a model for fine-tuning with a different window size through bi-cubic interpolation <cite> Swin Transformer Hierarchical Vision Transformer using Shifted Windows, p.5 </cite></p>
</blockquote>
<p><span class="math display">\[
\begin{table}
    \centering
\small
\addtolength{\tabcolsep}{-4.0pt}
\begin{tabular}
\Xhline{1.0pt}
\multirow{2}{*}{method} &amp; \multicolumn{4}{c|}{MSA in a stage (ms)} &amp; \multicolumn{3}{c}{Arch. (FPS)} \\
&amp; S1 &amp; S2 &amp; S3 &amp; S4 &amp; T &amp; S &amp; B \\
\hline
sliding window (naive) &amp; 122.5 &amp; 38.3 &amp; 12.1 &amp; 7.6 &amp; 183 &amp; 109 &amp; 77 \\
sliding window (kernel)  &amp; 7.6 &amp; 4.7 &amp; 2.7 &amp; 1.8 &amp; 488 &amp; 283 &amp; 187 \\
\hline
Performer~\cite{choromanski2020performer} &amp; 4.8 &amp; 2.8 &amp; 1.8 &amp; 1.5 &amp; 638 &amp; 370 &amp; 241 \\
\hline
window (w/o shifting) &amp; 2.8 &amp; 1.7 &amp; 1.2 &amp; 0.9 &amp; 770 &amp; 444 &amp; 280 \\
\hline
shifted window (padding) &amp; 3.3 &amp; 2.3 &amp; 1.9 &amp; 2.2 &amp; 670 &amp; 371 &amp; 236 \\
shifted window (cyclic)  &amp; 3.0 &amp; 1.9 &amp; 1.3 &amp; 1.0 &amp; 755 &amp; 437 &amp; 278 \\
\Xhline{1.0pt}
\end{tabular}
    \caption{Real speed of different self-attention computation methods and implementations on a V100 GPU. }
    \label{tab:ablation-selfatt-efficient}
\normalsize
\end{table}
\]</span></p>
</section>
</section>
<section id="others" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="others"><span class="header-section-number">1.6</span> Others</h2>
<p>é™¤äº†ä»¥ä¸Šå‡ ä¸ªï¼ŒSwin Transformer ä¸­è¿˜æœ‰å…¶ä»–Componentï¼Œæ¯”å¦‚ ï¼š</p>
<ul>
<li>Patch Embedding</li>
<li>Linear Projection</li>
<li>FeedForward</li>
<li>Layer Normalization åœ¨æ­¤ï¼Œå°±ä¸èµ˜è¿°äº†ï¼Œæœ‰éœ€è¦çš„åŒå­¦ï¼Œè¯·å‚è€ƒå‰ä¸€ç¯‡ <a href="../../../posts/PapersWithCode/02-vision-transformer/Vision-Transformer.html">Vision-Transformer</a>ï¼Œ æˆ–è€… <a href="../../../posts/PapersWithCode/01-transformer/Transformer.html">Transformer</a></li>
</ul>
</section>
<section id="downstream-tasks" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="downstream-tasks"><span class="header-section-number">1.7</span> Downstream Tasks</h2>
<p>å½“ä¸€åœºå›¾ç‰‡ä¼ å…¥Swin Transformerï¼Œ å®ƒå¯ä»¥æå–å‡ºå›¾ç‰‡çš„ç‰¹å¾ã€‚ <span class="math display">\[
\mathrm{z} = f_{\theta}(\mathrm{x}), \quad \text{where}\ \mathrm{x} \in \mathbb{R}^{3\times H \times W}, \mathrm{z} \in \mathbb{R}^{H'W' \times C}
\]</span></p>
<p>ä¸€å¼ å›¾ç‰‡è½¬åŒ–æˆäº† <span class="math inline">\(H'W'\)</span> ä¸ªç‰¹å¾ï¼Œæ¯ä¸ªç‰¹å¾çš„å¤§å°ä¸º $Cã€‚</p>
<p>Swin Transformer å¯ä»¥æœ‰å½“ä½œåŸºæœ¬çš„backboneï¼Œåœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥å¯¹ä¸‹æ¸¸è¿›è¡Œä¸åŒçš„ä»»åŠ¡ï¼Œæ¯”å¦‚ï¼š</p>
<ul>
<li>Image Classification</li>
<li>Object Detection</li>
<li>Semantic segmentation</li>
</ul>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å¦‚ä½•ç”¨Swin Transformeråœ¨ä¸åŒçš„ä»»åŠ¡ä¸­</p>
<p><img src="assets/swin-transformer-hier-representation.png" class="img-fluid"></p>
<section id="image-classification" class="level3" data-number="1.7.1">
<h3 data-number="1.7.1" class="anchored" data-anchor-id="image-classification"><span class="header-section-number">1.7.1</span> Image Classification</h3>
<p>å¯¹äº <span class="math inline">\(\mathrm{z}\)</span> çš„ hidden statesï¼Œæˆ‘ä»¬å¯ä»¥è¿›è¡Œä¸€ä¸ªAverage Poolingï¼Œå¯¹äºæ¯ä¸€ä¸ªç‰¹å¾æ±‚å‡å€¼ï¼Œç„¶åå†å°†è¿™ä¸ªä¼ å…¥ä¸€ä¸ªåˆ†ç±»å¤´ï¼Œå°±å¯ä»¥å¾—åˆ°æˆ‘ä»¬Classificationäº†ã€‚ä¸ <a href="../../../posts/PapersWithCode/02-vision-transformer/Vision-Transformer.html">Vision-Transformer</a> ä¸åŒçš„æ˜¯ï¼ŒSwin Transformer æ²¡æœ‰ <code>[CLS]</code> token æ¥å½“æ”¶é›†å…¨éƒ¨çš„ä¿¡æ¯ã€‚</p>
</section>
</section>
<section id="object-detection-semantic-segmentation" class="level2" data-number="1.8">
<h2 data-number="1.8" class="anchored" data-anchor-id="object-detection-semantic-segmentation"><span class="header-section-number">1.8</span> Object Detection &amp; Semantic segmentation</h2>
<p>Backbone (Swin Transformer)ï¼š</p>
<ul>
<li>Stage 1: [N, C1, H/4, W/4]</li>
<li>Stage 2: [N, C2, H/8, W/8]</li>
<li>Stage 3: [N, C3, H/16, W/16]</li>
<li>Stage 4: [N, C4, H/32, W/32]</li>
</ul>
<p>å¯ä»¥å¾—åˆ° FPN<span class="citation" data-cites="FeaturePyramidNetworks2017lin">(<a href="#ref-FeaturePyramidNetworks2017lin" role="doc-biblioref">Lin et al. 2017</a>)</span> to create a pyramid of feature maps suitable for detection.</p>
<div class="sourceCode" id="cb3" data-code-line-numbers=""><pre class="sourceCode numberSource text number-lines code-with-copy"><code class="sourceCode"><span id="cb3-1"><a href="#cb3-1"></a>{P2: [N, C, H/4, W/4], </span>
<span id="cb3-2"><a href="#cb3-2"></a> P3: [N, C, H/8, W/8], </span>
<span id="cb3-3"><a href="#cb3-3"></a> P4: [N, C, H/16, W/16], </span>
<span id="cb3-4"><a href="#cb3-4"></a> P5: [N, C, H/32, W/32]}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>æœ‰äº†è¿™äº›FPN ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥ç»“åˆä¸åŒçš„ç®—æ³•ï¼Œæ¥è¿›è¡Œä¸åŒçš„ä»»åŠ¡ï¼Œæ¯”å¦‚</p>
<p>ä¾‹å­ 1ï¼šç›®æ ‡æ£€æµ‹ (Object Detection)</p>
<p>ä»¥ Swin Transformer + Faster R-CNN <span class="citation" data-cites="FasterRCNNRealTime2016ren">(<a href="#ref-FasterRCNNRealTime2016ren" role="doc-biblioref">Ren et al. 2016</a>)</span> ä¸ºä¾‹ï¼š 1. è¾“å…¥å›¾åƒï¼šä¸€å¼  800Ã—1333 çš„ COCO æ•°æ®é›†å›¾ç‰‡ã€‚</p>
<pre data-code-line-numbers=""><code>3.  FPN (ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ)ï¼šå°†å¤šå°ºåº¦ç‰¹å¾èåˆï¼Œå½¢æˆç»Ÿä¸€çš„é‡‘å­—å¡”ç‰¹å¾ã€‚
4.  RPN (Region Proposal Network)ï¼šåœ¨ç‰¹å¾å›¾ä¸Šç”Ÿæˆå€™é€‰åŒºåŸŸã€‚
5.  RoI Headï¼šå¯¹å€™é€‰åŒºåŸŸè¿›è¡Œåˆ†ç±» (è½¦ã€äººã€ç‹—â€¦) å’Œè¾¹æ¡†å›å½’ã€‚
6.  è¾“å‡ºï¼šé¢„æµ‹ç»“æœï¼Œä¾‹å¦‚ï¼š
â€¢   â€œä¸€è¾†è½¦â€ â†’ è¾¹æ¡† (x1,y1,x2,y2) + ç±»åˆ« â€œcarâ€
â€¢   â€œä¸€ä¸ªäººâ€ â†’ è¾¹æ¡† + ç±»åˆ« â€œpersonâ€</code></pre>
<p><img src="assets/swin-object.png" class="img-fluid"> ğŸ‘‰ åœ¨ COCO æ•°æ®é›†ä¸Šï¼ŒSwin-T + Faster R-CNNæ¯” ResNet-50 + Faster R-CNN çš„ mAP æé«˜çº¦ 5~6 ä¸ªç‚¹ã€‚</p>
<p>è¯­ä¹‰åˆ†å‰² (Semantic Segmentation) <img src="assets/swin-UPerNet.png" class="img-fluid"> ä»¥ Swin Transformer + UPerNet<span class="citation" data-cites="UnifiedPerceptualParsing2018xiao">(<a href="#ref-UnifiedPerceptualParsing2018xiao" role="doc-biblioref">Xiao et al. 2018</a>)</span>ä¸ºä¾‹ï¼š 1. è¾“å…¥å›¾åƒï¼šä¸€å¼  512Ã—512 çš„ ADE20K æ•°æ®é›†å›¾ç‰‡ã€‚ 2. Backbone (Swin Transformer)ï¼šåŒæ ·è¾“å‡º 1/4, 1/8, 1/16, 1/32 å››ä¸ªå°ºåº¦ç‰¹å¾ã€‚ 3. FPN/UPerNet Headï¼š â€¢ å°†å¤šå±‚ç‰¹å¾èåˆï¼Œå¯¹åº”ä¸åŒè¯­ä¹‰å±‚çº§ã€‚ â€¢ åˆ©ç”¨èåˆåçš„ç‰¹å¾ç”Ÿæˆåƒç´ çº§é¢„æµ‹ã€‚ 4. é¢„æµ‹å›¾ (segmentation map)ï¼šå¤§å° 512Ã—512ï¼Œæ¯ä¸ªåƒç´ å±äºä¸€ä¸ªç±»åˆ«ã€‚ â€¢ [0,0] åƒç´  â†’ â€œskyâ€ â€¢ [100,150] åƒç´  â†’ â€œbuildingâ€ â€¢ [200,300] åƒç´  â†’ â€œroadâ€ 5. è¾“å‡ºï¼šå®Œæ•´çš„è¯­ä¹‰åˆ†å‰²å›¾ï¼Œæ¯ä¸ªåƒç´ éƒ½æœ‰ç±»åˆ«æ ‡ç­¾ã€‚</p>
<p>ğŸ‘‰ åœ¨ ADE20K ä¸Šï¼ŒSwin-L + UPerNet çš„ mIoU è¾¾åˆ° 53.5+ï¼Œæ¯”ä¼ ç»Ÿ CNN backbone æå‡æ˜¾è‘—ã€‚ å…·ä½“çš„å®ç°ç»†èŠ‚ï¼Œç­‰åˆ°ä»¥åæˆ‘ä»¬é˜…è¯»åˆ°å…³äºSegmentationçš„å†…å®¹åœ¨ï¼Œå†æ¥å®ç°</p>
</section>
<section id="training-details" class="level2" data-number="1.9">
<h2 data-number="1.9" class="anchored" data-anchor-id="training-details"><span class="header-section-number">1.9</span> Training Details</h2>
<blockquote class="blockquote">
<p>We employ an <strong>AdamW optimizer</strong> for 300 epochs using a <strong>cosine decay learning rate scheduler</strong> and 20 epochs of <strong>linear warm-up</strong>. A batch size of 1024, an initial learning rate of 0.001, and a <strong>weight decay</strong> of 0.05 are used. We include most of the augmentation and regularization strategies of in training, except for repeated augmentation and EMA, which do not enhance performance. <cite> Swin Transformer Hierarchical Vision Transformer using Shifted Windows, p.5 </cite></p>
</blockquote>
<section id="droppath" class="level3" data-number="1.9.1">
<h3 data-number="1.9.1" class="anchored" data-anchor-id="droppath"><span class="header-section-number">1.9.1</span> DropPath</h3>
<p>è®ºæ–‡ä¸­è¿˜ç”¨åˆ°äº† DropPath æ¥å½“ä½œä¸€ç§ Regularizationã€‚ DropPath ä¹Ÿç§°ä¹‹ä¸º Stochastic Depth <span class="citation" data-cites="DeepNetworksStochastic2016huang">(<a href="#ref-DeepNetworksStochastic2016huang" role="doc-biblioref">Huang et al. 2016</a>)</span> , å®ƒæ˜¯ä¸€ç§åº”ç”¨åœ¨Residual Networkï¼Œ åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œéšæœºä¸¢å¼ƒæ•´ä¸ª æ®‹å·®åˆ†æ”¯ (residual branch) æˆ– æ•´ä¸ªè·¯å¾„ (path)ã€‚å‡å°‘è¿‡æ‹Ÿåˆï¼ŒåŒæ—¶è®©æ¨¡å‹å­¦ä¼šä¾èµ–ä¸åŒæ·±åº¦çš„è·¯å¾„ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ã€‚ <img src="assets/Swin-Transformer-Drop-Path.png" class="img-fluid"></p>
<p>ä¸Dropout ä¸åŒçš„æ˜¯ï¼Œ Dropout ä¸¢å¼ƒçš„æ˜¯å•ä¸ªç¥ç»å…ƒçš„è¾“å‡ºï¼Œ è€ŒDropPath ä¸¢å¼ƒçš„æ˜¯æ•´ä¸ªæ®‹å·®åˆ†æ”¯ / æ•´å±‚ Block</p>
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 34%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th>ç‰¹æ€§</th>
<th>Dropout (ç»å…¸)</th>
<th>DropPath (Stochastic Depth)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ä¸¢å¼ƒå¯¹è±¡</td>
<td>å•ä¸ªç¥ç»å…ƒçš„è¾“å‡º</td>
<td>æ•´ä¸ªæ®‹å·®åˆ†æ”¯ / æ•´å±‚ Block</td>
</tr>
<tr class="even">
<td>åº”ç”¨ç²’åº¦</td>
<td>é€å…ƒç´  (element-wise)</td>
<td>å±‚çº§ (layer-wise)</td>
</tr>
<tr class="odd">
<td>ä½¿ç”¨åœºæ™¯</td>
<td>å…¨è¿æ¥å±‚ã€CNNã€RNN ç­‰</td>
<td>æ®‹å·®ç½‘ç»œã€Transformer ç­‰</td>
</tr>
<tr class="even">
<td>æ¨ç†é˜¶æ®µæ•ˆæœ</td>
<td>ä¸ä¸¢å¼ƒï¼Œä½¿ç”¨ç¼©æ”¾è¡¥å¿</td>
<td>ä¸ä¸¢å¼ƒï¼Œä¿ç•™å®Œæ•´è·¯å¾„</td>
</tr>
<tr class="odd">
<td>ä½œç”¨</td>
<td>å‡å°‘ç¥ç»å…ƒè¿‡æ‹Ÿåˆ</td>
<td>é˜²æ­¢æ·±å±‚ç½‘ç»œè¿‡æ‹Ÿåˆã€æå‡ç¨³å®šæ€§</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb5" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="kw">def</span> drop_path(x, drop_prob: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.0</span>, training: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb5-2"><a href="#cb5-2"></a>    <span class="cf">if</span> drop_prob <span class="op">==</span> <span class="fl">0.0</span> <span class="kw">or</span> <span class="kw">not</span> training:</span>
<span id="cb5-3"><a href="#cb5-3"></a>        <span class="cf">return</span> x</span>
<span id="cb5-4"><a href="#cb5-4"></a>    keep_prob <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> drop_prob</span>
<span id="cb5-5"><a href="#cb5-5"></a>    shape <span class="op">=</span> (x.shape[<span class="dv">0</span>],) <span class="op">+</span> (<span class="dv">1</span>,) <span class="op">*</span> (x.ndim <span class="op">-</span> <span class="dv">1</span>)  <span class="co"># work with diff dim tensors, not just 2D ConvNets</span></span>
<span id="cb5-6"><a href="#cb5-6"></a>    random_tensor <span class="op">=</span> keep_prob <span class="op">+</span> torch.rand(shape, dtype<span class="op">=</span>x.dtype, device<span class="op">=</span>x.device)</span>
<span id="cb5-7"><a href="#cb5-7"></a>    random_tensor.floor_()  <span class="co"># binarize</span></span>
<span id="cb5-8"><a href="#cb5-8"></a>    output <span class="op">=</span> x.div(keep_prob) <span class="op">*</span> random_tensor</span>
<span id="cb5-9"><a href="#cb5-9"></a>    <span class="cf">return</span> output</span>
<span id="cb5-10"><a href="#cb5-10"></a></span>
<span id="cb5-11"><a href="#cb5-11"></a></span>
<span id="cb5-12"><a href="#cb5-12"></a><span class="kw">class</span> DropPath(nn.Module):</span>
<span id="cb5-13"><a href="#cb5-13"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, drop_prob<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb5-14"><a href="#cb5-14"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-15"><a href="#cb5-15"></a>        <span class="va">self</span>.drop_prob <span class="op">=</span> drop_prob</span>
<span id="cb5-16"><a href="#cb5-16"></a></span>
<span id="cb5-17"><a href="#cb5-17"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb5-18"><a href="#cb5-18"></a>        <span class="cf">return</span> drop_path(x, <span class="va">self</span>.drop_prob, <span class="va">self</span>.training)</span>
<span id="cb5-19"><a href="#cb5-19"></a>        </span>
<span id="cb5-20"><a href="#cb5-20"></a></span>
<span id="cb5-21"><a href="#cb5-21"></a><span class="kw">class</span> SwinTransformerBlock(nn.Module):</span>
<span id="cb5-22"><a href="#cb5-22"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb5-23"><a href="#cb5-23"></a>        ...</span>
<span id="cb5-24"><a href="#cb5-24"></a>        <span class="va">self</span>.drop_path <span class="op">=</span> DropPath(drop_path) <span class="cf">if</span> drop_path <span class="op">&gt;</span> <span class="fl">0.0</span> <span class="cf">else</span> nn.Identity()</span>
<span id="cb5-25"><a href="#cb5-25"></a>        </span>
<span id="cb5-26"><a href="#cb5-26"></a>    </span>
<span id="cb5-27"><a href="#cb5-27"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb5-28"><a href="#cb5-28"></a>        shortcut <span class="op">=</span> x </span>
<span id="cb5-29"><a href="#cb5-29"></a>        ... <span class="co"># Attention </span></span>
<span id="cb5-30"><a href="#cb5-30"></a>        x <span class="op">=</span> shortcut <span class="op">+</span> <span class="va">self</span>.drop_path(x)</span>
<span id="cb5-31"><a href="#cb5-31"></a>        </span>
<span id="cb5-32"><a href="#cb5-32"></a>        shortcut <span class="op">=</span> x </span>
<span id="cb5-33"><a href="#cb5-33"></a>        ... <span class="co"># FFN</span></span>
<span id="cb5-34"><a href="#cb5-34"></a>        x <span class="op">=</span> shortcut <span class="op">+</span> <span class="va">self</span>.drop_path(x)</span>
<span id="cb5-35"><a href="#cb5-35"></a>        </span>
<span id="cb5-36"><a href="#cb5-36"></a>        ...</span>
<span id="cb5-37"><a href="#cb5-37"></a>        </span>
<span id="cb5-38"><a href="#cb5-38"></a>        <span class="cf">return</span> x </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout-tldr">
<p>ğŸ“ <span style="color:rgb(146, 208, 80)">TAKEAWAY</span> DropPathï¼ˆä¹Ÿå« Stochastic Depthï¼‰æ˜¯ä¸€ç§æ­£åˆ™åŒ–æ–¹æ³•ï¼Œå®ƒåœ¨è®­ç»ƒæ—¶éšæœºè·³è¿‡ï¼ˆä¸¢å¼ƒï¼‰æ•´ä¸ªç½‘ç»œå±‚æˆ–åˆ†æ”¯çš„è®¡ç®—ï¼Œä»¥å‡å°‘è¿‡æ‹Ÿåˆå¹¶æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
</div>
</section>
<section id="gradient-checkpoint" class="level3" data-number="1.9.2">
<h3 data-number="1.9.2" class="anchored" data-anchor-id="gradient-checkpoint"><span class="header-section-number">1.9.2</span> Gradient Checkpoint</h3>
<p>åœ¨æ­¤ï¼Œæˆ‘ä»¬åœ¨ä»‹ç»ä¸€ä¸ªè®­ç»ƒæ–¹æ³•ï¼Œç”¨äºåŠ é€Ÿè®­ç»ƒï¼Œå«åšGradient Checkpointåˆå«åšActivation Checkpointï¼Œ ç”¨PyTorhå®ç°ï¼Œæ˜¯å¾ˆå®¹æ˜“çš„ çš„ï¼Œæˆ‘ä»¬åªéœ€è¦call <a href="https://docs.pytorch.org/docs/stable/checkpoint.html"><code>utils.checkpoint</code></a></p>
<p>æ­£å¸¸è®­ç»ƒæµç¨‹ï¼š åœ¨å‰å‘ä¼ æ’­ï¼ˆforwardï¼‰æ—¶ï¼Œæ¯ä¸€å±‚çš„ä¸­é—´æ¿€æ´»å€¼ï¼ˆactivationï¼‰éƒ½ä¼šä¿å­˜ä¸‹æ¥ï¼Œä»¥ä¾¿åå‘ä¼ æ’­ï¼ˆbackwardï¼‰æ—¶ç”¨æ¥è®¡ç®—æ¢¯åº¦ã€‚ é—®é¢˜æ˜¯ï¼šä¿å­˜æ‰€æœ‰ä¸­é—´æ¿€æ´»å€¼ä¼šæ¶ˆè€—å¤§é‡æ˜¾å­˜ï¼ˆGPU memoryï¼‰ã€‚ â€¢ Gradient Checkpoint çš„æ€è·¯ï¼š å¹¶ä¸æ˜¯ä¿å­˜æ‰€æœ‰æ¿€æ´»å€¼ï¼Œè€Œæ˜¯åªåœ¨éƒ¨åˆ†å…³é”®èŠ‚ç‚¹ï¼ˆcheckpointï¼‰ä¿å­˜æ¿€æ´»ã€‚ å¯¹äºæœªä¿å­˜çš„æ¿€æ´»å€¼ï¼Œåœ¨åå‘ä¼ æ’­æ—¶é‡æ–°å†è·‘ä¸€æ¬¡å‰å‘è®¡ç®—æ¥å¾—åˆ°å®ƒä»¬ï¼Œä»è€ŒèŠ‚çœæ˜¾å­˜ã€‚</p>
<p>æ¢å¥è¯è¯´ï¼šç”¨è®¡ç®—æ¢æ˜¾å­˜ã€‚</p>
<p>ğŸ”¹ å·¥ä½œæœºåˆ¶ 1. åœ¨å‰å‘ä¼ æ’­æ—¶ï¼š â€¢ æ¨¡å‹è¢«åˆ‡åˆ†æˆè‹¥å¹²å—ï¼ˆsegmentsï¼‰ã€‚ â€¢ åªä¿å­˜æ¯ä¸€å—çš„è¾“å…¥ï¼Œä¸¢å¼ƒä¸­é—´çš„æ¿€æ´»ã€‚ 2. åœ¨åå‘ä¼ æ’­æ—¶ï¼š â€¢ éœ€è¦ç”¨åˆ°æ¢¯åº¦æ—¶ï¼Œé‡æ–°å¯¹é‚£ä¸€å—åšä¸€æ¬¡ forward æ¥æ¢å¤æ¿€æ´»ã€‚ â€¢ ç„¶åæ­£å¸¸è®¡ç®—æ¢¯åº¦ã€‚</p>
<pre data-code-line-numbers=""><code>â€¢   å¢åŠ è®¡ç®—å¼€é”€ï¼šå› ä¸ºè¦åœ¨ backward æ—¶é‡æ–°åšä¸€æ¬¡ forwardã€‚
â€¢   ä¸€èˆ¬ä¼šå¸¦æ¥ 20%ï½30% é¢å¤–çš„è®­ç»ƒæ—¶é—´ã€‚</code></pre>
<div class="sourceCode" id="cb7" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="im">import</span> torch</span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="im">from</span> torch.utils.checkpoint <span class="im">import</span> checkpoint</span>
<span id="cb7-4"><a href="#cb7-4"></a></span>
<span id="cb7-5"><a href="#cb7-5"></a><span class="kw">class</span> MyModule(nn.Module):</span>
<span id="cb7-6"><a href="#cb7-6"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb7-7"><a href="#cb7-7"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb7-8"><a href="#cb7-8"></a>        <span class="va">self</span>.layer1 <span class="op">=</span> nn.Linear(<span class="dv">1024</span>, <span class="dv">1024</span>)</span>
<span id="cb7-9"><a href="#cb7-9"></a>        <span class="va">self</span>.layer2 <span class="op">=</span> nn.Linear(<span class="dv">1024</span>, <span class="dv">1024</span>)</span>
<span id="cb7-10"><a href="#cb7-10"></a></span>
<span id="cb7-11"><a href="#cb7-11"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb7-12"><a href="#cb7-12"></a>        <span class="kw">def</span> custom_forward(<span class="op">*</span>inputs):</span>
<span id="cb7-13"><a href="#cb7-13"></a>            <span class="cf">return</span> <span class="va">self</span>.layer2(<span class="va">self</span>.layer1(<span class="op">*</span>inputs))</span>
<span id="cb7-14"><a href="#cb7-14"></a>        </span>
<span id="cb7-15"><a href="#cb7-15"></a>        <span class="co"># å¯¹è¿™éƒ¨åˆ†ä½¿ç”¨ checkpoint</span></span>
<span id="cb7-16"><a href="#cb7-16"></a>        x <span class="op">=</span> checkpoint(custom_forward, x)</span>
<span id="cb7-17"><a href="#cb7-17"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout-tldr">
<p>ğŸ“ <span style="color:rgb(146, 208, 80)">TAKEAWAY</span> Gradient Checkpointing æ˜¯ä¸€ç§ ç”¨é¢å¤–è®¡ç®—æ¢æ˜¾å­˜ çš„æ–¹æ³•ï¼Œé€šè¿‡åœ¨å‰å‘ä¼ æ’­æ—¶å°‘å­˜æ¿€æ´»ï¼Œåå‘ä¼ æ’­æ—¶é‡ç®—ï¼Œèƒ½è®©å¤§æ¨¡å‹åœ¨æœ‰é™æ˜¾å­˜ä¸‹å®Œæˆè®­ç»ƒã€‚</p>
</div>
</section>
</section>
<section id="swin-v2" class="level2" data-number="1.10">
<h2 data-number="1.10" class="anchored" data-anchor-id="swin-v2"><span class="header-section-number">1.10</span> Swin V2</h2>
<p>â€œSwin V2â€ <span class="citation" data-cites="SwinTransformerV22022liu">(<a href="#ref-SwinTransformerV22022liu" role="doc-biblioref">Liu et al. 2022</a>)</span> æ˜¯åœ¨åŸå§‹ Swin Transformer çš„åŸºç¡€ä¸Šï¼Œä¸ºäº†æ›´å¥½åœ° <strong>æ‰©å±•æ¨¡å‹å®¹é‡ï¼ˆæ›´å¤šå‚æ•°ï¼‰</strong>ã€<strong>å¤„ç†é«˜åˆ†è¾¨ç‡è¾“å…¥</strong> ä»¥åŠ <strong>æé«˜è®­ç»ƒç¨³å®šæ€§</strong> æ‰€åšçš„ä¸€ç³»åˆ—æ”¹è¿›ã€‚ åœ¨è§†è§‰ä»»åŠ¡ä¸­ï¼ŒTransformer æ¨¡å‹è‹¥è¦å˜å¾—æ›´å¼ºï¼ˆæ›´å¤šå‚æ•°ã€æ›´é«˜åˆ†è¾¨ç‡è¾“å…¥ã€æ›´å¤šå±‚æ•°ï¼‰å°±ä¼šé‡åˆ°å‡ ä¸ªæŒ‘æˆ˜ï¼š 1. è®­ç»ƒä¸ç¨³å®šï¼šéšç€æ¨¡å‹å˜æ·±ã€é€šé“å˜å®½ï¼Œå†…éƒ¨æ¿€æ´»çš„å¹…åº¦å¯èƒ½æ€¥å‰§å¢é•¿ï¼Œå¯¼è‡´æ¢¯åº¦ã€æ•°å€¼ä¸ç¨³å®šã€‚ 2. åˆ†è¾¨ç‡è¿ç§»é—®é¢˜ï¼šæ¨¡å‹åœ¨ä½åˆ†è¾¨ç‡ä¸‹é¢„è®­ç»ƒï¼ˆä¾‹å¦‚ 224Ã—224ï¼‰åï¼Œç”¨åœ¨é«˜åˆ†è¾¨ç‡ï¼ˆä¾‹å¦‚ 1,536Ã—1,536ï¼‰æˆ–ä¸åŒçª—å£å°ºå¯¸æ—¶è¡¨ç°ä¼šä¸‹é™ã€‚ 3. å¯¹æ ‡æ³¨æ•°æ®çš„è¿‡åº¦ä¾èµ–ï¼šå¤§æ¨¡å‹éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®æ‰èƒ½è®­ç»ƒå¾—å¥½ã€‚</p>
<p>Swin V2 å°±æ˜¯ä¸ºäº†å…‹æœè¿™äº›éšœç¢ï¼Œæ”¯æŒè®­ç»ƒè¶…å¤§æ¨¡å‹ï¼ˆå¦‚ 30 äº¿å‚æ•°çº§åˆ«ï¼‰ï¼ŒåŒæ—¶èƒ½å¤„ç†å¤§å°ºå¯¸è¾“å…¥ <img src="assets/Swin-Transformer-SwinV2.png" class="img-fluid"></p>
<section id="post-normalization" class="level3" data-number="1.10.1">
<h3 data-number="1.10.1" class="anchored" data-anchor-id="post-normalization"><span class="header-section-number">1.10.1</span> Post normalization</h3>
<div class="sourceCode" id="cb8" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a><span class="kw">class</span> SwinTransformerBlock(nn.Module):</span>
<span id="cb8-2"><a href="#cb8-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb8-3"><a href="#cb8-3"></a>        ...</span>
<span id="cb8-4"><a href="#cb8-4"></a>        <span class="va">self</span>.drop_path <span class="op">=</span> DropPath(drop_path) <span class="cf">if</span> drop_path <span class="op">&gt;</span> <span class="fl">0.0</span> <span class="cf">else</span> nn.Identity()</span>
<span id="cb8-5"><a href="#cb8-5"></a>        </span>
<span id="cb8-6"><a href="#cb8-6"></a>    </span>
<span id="cb8-7"><a href="#cb8-7"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb8-8"><a href="#cb8-8"></a>        shortcut <span class="op">=</span> x </span>
<span id="cb8-9"><a href="#cb8-9"></a>        ... <span class="co"># Attention </span></span>
<span id="cb8-10"><a href="#cb8-10"></a>        x <span class="op">=</span> shortcut <span class="op">+</span> <span class="va">self</span>.drop_path(<span class="va">self</span>.norm1(x))</span>
<span id="cb8-11"><a href="#cb8-11"></a>        </span>
<span id="cb8-12"><a href="#cb8-12"></a>        shortcut <span class="op">=</span> x </span>
<span id="cb8-13"><a href="#cb8-13"></a>        ... <span class="co"># FFN</span></span>
<span id="cb8-14"><a href="#cb8-14"></a>        x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.drop_path(<span class="va">self</span>.norm2(<span class="va">self</span>.mlp(x)))</span>
<span id="cb8-15"><a href="#cb8-15"></a>        </span>
<span id="cb8-16"><a href="#cb8-16"></a>        ...</span>
<span id="cb8-17"><a href="#cb8-17"></a>        </span>
<span id="cb8-18"><a href="#cb8-18"></a>        <span class="cf">return</span> x </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="scaled-cosine-attention" class="level3" data-number="1.10.2">
<h3 data-number="1.10.2" class="anchored" data-anchor-id="scaled-cosine-attention"><span class="header-section-number">1.10.2</span> Scaled cosine attention</h3>
<div class="sourceCode" id="cb9" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="kw">class</span> WindowAttention:</span>
<span id="cb9-2"><a href="#cb9-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,):</span>
<span id="cb9-3"><a href="#cb9-3"></a>    </span>
<span id="cb9-4"><a href="#cb9-4"></a>        ...</span>
<span id="cb9-5"><a href="#cb9-5"></a>        <span class="va">self</span>.logit_scale <span class="op">=</span> nn.Parameter(torch.log(<span class="dv">10</span> <span class="op">*</span> torch.ones((num_heads, <span class="dv">1</span>, <span class="dv">1</span>))), requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-6"><a href="#cb9-6"></a>        ...</span>
<span id="cb9-7"><a href="#cb9-7"></a>    </span>
<span id="cb9-8"><a href="#cb9-8"></a>    </span>
<span id="cb9-9"><a href="#cb9-9"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb9-10"><a href="#cb9-10"></a>        attn <span class="op">=</span> (F.normalize(q, dim<span class="op">=-</span><span class="dv">1</span>) <span class="op">@</span> F.normalize(k, dim<span class="op">=-</span><span class="dv">1</span>).transpose(<span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb9-11"><a href="#cb9-11"></a>        logit_scale <span class="op">=</span> torch.clamp(<span class="va">self</span>.logit_scale, <span class="bu">max</span><span class="op">=</span>torch.log(torch.tensor(<span class="fl">1.</span> <span class="op">/</span> <span class="fl">0.01</span>))).exp()</span>
<span id="cb9-12"><a href="#cb9-12"></a>        attn <span class="op">=</span> attn <span class="op">*</span> logit_scale</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="log-spaced-continuous-position-biaslog-cpb" class="level3" data-number="1.10.3">
<h3 data-number="1.10.3" class="anchored" data-anchor-id="log-spaced-continuous-position-biaslog-cpb"><span class="header-section-number">1.10.3</span> Log-spaced Continuous Position Bias(Log-CPB)</h3>
<p>log-spaced continuous position bias approach to address the issue in transferring across window resolutions</p>
<p><span class="math display">\[
\begin{split}
\widehat{\Delta x} &amp;= \operatorname{sign}(x) \cdot \log(1 + |\Delta x|) \\
\widehat{\Delta y} &amp;= \operatorname{sign}(y) \cdot \log(1 + |\Delta y|)
\end{split}
\]</span></p>
<div class="sourceCode" id="cb10" data-code-line-numbers=""><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="va">self</span>.cpb_mlp <span class="op">=</span> nn.Sequential(nn.Linear(<span class="dv">2</span>, <span class="dv">512</span>, bias<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb10-2"><a href="#cb10-2"></a>                             nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb10-3"><a href="#cb10-3"></a>                             nn.Linear(<span class="dv">512</span>, num_heads, bias<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb10-4"><a href="#cb10-4"></a>                             </span>
<span id="cb10-5"><a href="#cb10-5"></a><span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb10-6"><a href="#cb10-6"></a>    relative_position_bias_table <span class="op">=</span> <span class="va">self</span>.cpb_mlp(<span class="va">self</span>.relative_coords_table).view(<span class="op">-</span><span class="dv">1</span>, <span class="va">self</span>.num_heads)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="summary" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Summary</h1>
<p>åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†ä»€ä¹ˆæ˜¯Swin Transformerã€‚Swin Transformer åœ¨ ViT çš„åŸºç¡€ä¸Šå¼•å…¥äº† å±‚æ¬¡åŒ–ç»“æ„() å’Œ åŸºäºçª—å£çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚é€šè¿‡åœ¨å›ºå®šçª—å£å†…è®¡ç®—æ³¨æ„åŠ›ï¼ˆW-MSAï¼‰ï¼Œæ˜¾è‘—é™ä½è®¡ç®—å¤æ‚åº¦ï¼›å†åˆ©ç”¨ ç§»ä½çª—å£ï¼ˆSW-MSAï¼‰ ä¸ å¾ªç¯ç§»ä½ æŠ€å·§ï¼Œå®ç°è·¨çª—å£çš„ä¿¡æ¯äº¤äº’ã€‚ä¸æ­¤åŒæ—¶ï¼ŒPatch Merging é€æ­¥é™ä½åˆ†è¾¨ç‡ã€å¢åŠ é€šé“æ•°ï¼Œå½¢æˆç±»ä¼¼ CNN çš„é‡‘å­—å¡”ç‰¹å¾ï¼Œé€‚åˆæ£€æµ‹ä¸åˆ†å‰²ç­‰å¤šå°ºåº¦ä»»åŠ¡ã€‚</p>
<p>æ­¤å¤–ï¼ŒSwin Transformer ä½¿ç”¨ ç›¸å¯¹ä½ç½®åç½® æ¥å¢å¼ºå±€éƒ¨å»ºæ¨¡èƒ½åŠ›ï¼Œå¹¶é€šè¿‡ DropPath ç­‰æ­£åˆ™åŒ–æ–¹æ³•æå‡è®­ç»ƒç¨³å®šæ€§ã€‚åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­ï¼ˆåˆ†ç±»ã€æ£€æµ‹ã€åˆ†å‰²ï¼‰ï¼ŒSwin Transformer è¡¨ç°ä¼˜äºä¼ ç»Ÿ CNNã€‚å‡çº§ç‰ˆ Swin V2 è¿›ä¸€æ­¥æå‡ºäº† æ®‹å·®åå½’ä¸€åŒ–ã€ç¼©æ”¾ä½™å¼¦æ³¨æ„åŠ› å’Œ å¯¹æ•°è¿ç»­ä½ç½®åç½® ç­‰æ”¹è¿›ï¼Œä½¿å…¶èƒ½å¤Ÿæ‰©å±•åˆ°æ›´å¤§æ¨¡å‹å’Œæ›´é«˜åˆ†è¾¨ç‡è¾“å…¥ã€‚</p>
<p>é™¤äº†æ¨¡å‹å¤–ï¼Œæˆ‘ä»¬è¿˜å­¦ä¹ åˆ°äº†ä¸¤ä¸ªGeneralçš„è®­ç»ƒæ–¹æ³•ï¼Œä¸€ä¸ªæ˜¯ DropPathï¼Œå¦ä¸€ä¸ªæ˜¯Gradient Checkpointã€‚</p>
</section>
<section id="key-concept-check-table" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Key Concept Check Table</h1>
<table class="table">
<colgroup>
<col style="width: 37%">
<col style="width: 62%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Concept</strong></th>
<th><strong>Explanation</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Hierarchical Representationï¼ˆå±‚çº§è¡¨ç¤ºï¼‰</strong></td>
<td>é€šè¿‡ <strong>Patch Merging</strong> é€å±‚é™ä½åˆ†è¾¨ç‡ã€å¢åŠ é€šé“æ•°ï¼Œå½¢æˆç±»ä¼¼ CNN çš„å¤šå°ºåº¦ç‰¹å¾å›¾ï¼Œé€‚åˆæ£€æµ‹/åˆ†å‰²ä»»åŠ¡ã€‚</td>
</tr>
<tr class="even">
<td><strong>Patch Mergingï¼ˆè¡¥ä¸åˆå¹¶ï¼‰</strong></td>
<td>å°† (2 ) é‚»è¿‘ patch æ‹¼æ¥ï¼Œå†é€šè¿‡çº¿æ€§æŠ•å½±ï¼Œå‡å°‘ç©ºé—´å°ºå¯¸ã€å¢åŠ ç‰¹å¾ç»´åº¦ã€‚</td>
</tr>
<tr class="odd">
<td><strong>Window-based Self-Attention (W-MSA)</strong></td>
<td>å°†ç‰¹å¾å›¾åˆ’åˆ†ä¸ºå›ºå®šå¤§å°çš„çª—å£ï¼ˆå¦‚ (7 )ï¼‰ï¼Œä»…åœ¨çª—å£å†…è®¡ç®—è‡ªæ³¨æ„åŠ›ï¼Œå¤§å¹…é™ä½è®¡ç®—å¤æ‚åº¦ã€‚</td>
</tr>
<tr class="even">
<td><strong>Shifted Windows (SW-MSA)</strong></td>
<td>åœ¨ä¸‹ä¸€å±‚å°†çª—å£æ•´ä½“å¹³ç§»ï¼ˆå¦‚ç§»åŠ¨ä¸€åŠçª—å£å¤§å°ï¼‰ï¼Œè®©è·¨çª—å£ token å¾—ä»¥äº¤äº’ï¼Œå®ç°å…¨å±€å»ºæ¨¡ã€‚</td>
</tr>
<tr class="odd">
<td><strong>Cyclic Shiftï¼ˆå¾ªç¯ç§»ä½ï¼‰</strong></td>
<td>å®ç° Shifted Window çš„å…³é”®æŠ€å·§ï¼šé€šè¿‡å¾ªç¯ç§»ä½ï¼ˆcyclic shiftï¼‰å®ç°çª—å£åç§»ï¼Œä¿è¯å®ç°é«˜æ•ˆä¸”æ˜“äºå¹¶è¡Œè®¡ç®—ã€‚</td>
</tr>
<tr class="even">
<td><strong>Relative Position Biasï¼ˆç›¸å¯¹ä½ç½®åç½®ï¼‰</strong></td>
<td>æ¯ä¸ªçª—å£å†…ä¸ºä¸åŒç›¸å¯¹ä½ç½®çš„ token å¼•å…¥å¯å­¦ä¹ åç½®ï¼Œå¢å¼ºå±€éƒ¨æ„ŸçŸ¥ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚</td>
</tr>
<tr class="odd">
<td><strong>DropPathï¼ˆéšæœºæ·±åº¦ / Stochastic Depthï¼‰</strong></td>
<td>åœ¨è®­ç»ƒä¸­éšæœºä¸¢å¼ƒéƒ¨åˆ†æ®‹å·®è·¯å¾„ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆå¹¶å¢å¼ºæ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼ˆç±»ä¼¼äº dropout åœ¨å±‚çº§ä¸Šçš„åº”ç”¨ï¼‰ã€‚</td>
</tr>
<tr class="even">
<td><strong>Gradient Checkpointï¼ˆæ¢¯åº¦æ£€æŸ¥ç‚¹ï¼‰</strong></td>
<td>åœ¨è®­ç»ƒæ—¶èŠ‚çœæ˜¾å­˜çš„æŠ€å·§ï¼šé€šè¿‡é‡ç®—ä¸­é—´æ¿€æ´»å€¼æ¢å–æ˜¾å­˜ç©ºé—´ï¼Œä»è€Œèƒ½è®­ç»ƒæ›´æ·±ã€æ›´å¤§çš„æ¨¡å‹ã€‚</td>
</tr>
</tbody>
</table>
</section>
<section id="q-a" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Q &amp; A</h1>
<p>Question: ä¸ºä»€ä¹ˆ ViT çš„å…¨å±€æ³¨æ„åŠ›ä¸é€‚åˆé«˜åˆ†è¾¨ç‡å›¾åƒï¼Ÿ è®¡ç®—å¤æ‚åº¦æ˜¯äºŒæ¬¡æ–¹ï¼Œå›¾åƒå°ºå¯¸è¶Šå¤§ï¼Œtoken æ•°è¶Šå¤šï¼Œä»£ä»·ä¸å¯æ¥å—ã€‚</p>
<p>Question: çª—å£ä¹‹é—´çš„ä¿¡æ¯å¦‚ä½•æµé€šï¼Ÿ é€šè¿‡ shifted window æœºåˆ¶ï¼Œä½¿å¾—çª—å£åˆ’åˆ†äº¤é”™ï¼Œä»è€Œä»¤åŸæœ¬å±äºä¸åŒçª—å£çš„ token è¿›å…¥åŒä¸€çª—å£ï¼Œä»è€Œå®ç°è·¨çª—å£ attentionã€‚</p>
<p>Q3. Swin Transformer ä¸ºä»€ä¹ˆèƒ½ä½œä¸ºæ£€æµ‹å’Œåˆ†å‰²çš„éª¨å¹²ï¼Ÿ ç­”ï¼šå› ä¸ºå®ƒæ„å»ºäº†å±‚çº§ç‰¹å¾å›¾ï¼Œèƒ½å’Œ FPN ç­‰ç»“æ„è‡ªç„¶å¯¹æ¥ï¼Œåƒ ResNet ä¸€æ ·å¤šå°ºåº¦ã€‚</p>
<p>Q4. ç›¸å¯¹ä½ç½®åç½®ä¸ºä»€ä¹ˆæ¯”ç»å¯¹ä½ç½®ç¼–ç æ›´å¥½ï¼Ÿ ç­”ï¼šç›¸å¯¹ä½ç½®ç¼–ç å¯å¤ç”¨åœ¨ä¸åŒåˆ†è¾¨ç‡ä¸‹çš„çª—å£ï¼Œæ³›åŒ–æ€§æ›´å¼ºï¼Œæ›´è´´åˆå›¾åƒå±€éƒ¨å…³ç³»ã€‚</p>
<p>Q7. Swin çš„å±€é™æ€§æœ‰å“ªäº›ï¼Ÿ ç­”ï¼šçª—å£å¤§å°å›ºå®šï¼Œè¿œè·ç¦»ä¾èµ–è¦å †å å¤šå±‚ï¼›å®ç°å¤æ‚åº¦é«˜ï¼›å¯¹è¶…é«˜åˆ†è¾¨ç‡å›¾åƒä»ç„¶è®¡ç®—é‡å¤§ã€‚</p>
<p>Question: shifted window çš„ mask æ˜¯æ€æ ·è®¾è®¡çš„ï¼Ÿ å½“çª—å£ç§»åŠ¨åï¼Œä¸€äº› token ä¼šè·¨è¶Šæ—§çª—å£è¾¹ç•Œï¼Œä½¿å¾—å®ƒä»¬å’Œä¸åº”äº¤äº’çš„ token åœ¨åŒä¸€ä¸ªæ–°çª—å£å†…ã€‚æ­¤æ—¶ä½¿ç”¨ maskï¼ŒæŠŠé‚£äº›ä¸åˆæ³• token å¯¹çš„ attention æƒé‡è®¾ä¸ºæå°å€¼ï¼ˆæˆ–ç¦æ­¢ï¼‰ï¼Œä»¥é˜²å®ƒä»¬äº¤äº’ã€‚</p>
<p>Q8. Swin V2 åšäº†å“ªäº›æ”¹è¿›ï¼Ÿ ç­”ï¼šæå‡º residual post-normã€æ›´ç¨³å®šçš„æ³¨æ„åŠ›ç¼©æ”¾ã€å¯¹æ•°è¿ç»­ä½ç½®åç½®ã€æ›´å¥½çš„è‡ªç›‘ç£è®­ç»ƒï¼ˆSimMIMï¼‰ã€‚</p>
</section>
<section id="related-resource-further-reading" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Related resource &amp; Further Reading</h1>
<p>åŸå§‹è®ºæ–‡ - Swin Transformer: Hierarchical Vision Transformer using Shifted Windows - Swin Transformer V2: Scaling Up Capacity and Resolution</p>
<p>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows Video Swin Transformer<span class="citation" data-cites="VideoSwinTransformer2021liu">(<a href="#ref-VideoSwinTransformer2021liu" role="doc-biblioref">Liu, Ning, et al. 2021</a>)</span> å°±æ˜¯Swin Transformeråœ¨Videoçš„åº”ç”¨ã€‚ Swin Transformer å®˜æ–¹å®ç°ï¼š<a href="https://github.com/microsoft/Swin-Transformer">GitHub Link</a></p>



</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-DeepNetworksStochastic2016huang" class="csl-entry" role="listitem">
Huang, Gao, Yu Sun, Zhuang Liu, Daniel Sedra, and Kilian Weinberger. 2016. <span>â€œDeep <span>Networks</span> with <span>Stochastic Depth</span>.â€</span> July 28, 2016. <a href="https://doi.org/10.48550/arXiv.1603.09382">https://doi.org/10.48550/arXiv.1603.09382</a>.
</div>
<div id="ref-FeaturePyramidNetworks2017lin" class="csl-entry" role="listitem">
Lin, Tsung-Yi, Piotr DollÃ¡r, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. 2017. <span>â€œFeature <span>Pyramid Networks</span> for <span>Object Detection</span>.â€</span> April 19, 2017. <a href="https://doi.org/10.48550/arXiv.1612.03144">https://doi.org/10.48550/arXiv.1612.03144</a>.
</div>
<div id="ref-SwinTransformerV22022liu" class="csl-entry" role="listitem">
Liu, Ze, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, et al. 2022. <span>â€œSwin <span>Transformer V2</span>: <span>Scaling Up Capacity</span> and <span>Resolution</span>.â€</span> April 11, 2022. <a href="https://doi.org/10.48550/arXiv.2111.09883">https://doi.org/10.48550/arXiv.2111.09883</a>.
</div>
<div id="ref-SwinTransformerHierarchical2021liu" class="csl-entry" role="listitem">
Liu, Ze, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. 2021. <span>â€œSwin <span>Transformer</span>: <span>Hierarchical Vision Transformer</span> Using <span>Shifted Windows</span>.â€</span> August 17, 2021. <a href="https://doi.org/10.48550/arXiv.2103.14030">https://doi.org/10.48550/arXiv.2103.14030</a>.
</div>
<div id="ref-VideoSwinTransformer2021liu" class="csl-entry" role="listitem">
Liu, Ze, Jia Ning, Yue Cao, Yixuan Wei, Zheng Zhang, Stephen Lin, and Han Hu. 2021. <span>â€œVideo <span>Swin Transformer</span>.â€</span> June 24, 2021. <a href="https://doi.org/10.48550/arXiv.2106.13230">https://doi.org/10.48550/arXiv.2106.13230</a>.
</div>
<div id="ref-FasterRCNNRealTime2016ren" class="csl-entry" role="listitem">
Ren, Shaoqing, Kaiming He, Ross Girshick, and Jian Sun. 2016. <span>â€œFaster <span>R-CNN</span>: <span>Towards Real-Time Object Detection</span> with <span>Region Proposal Networks</span>.â€</span> January 6, 2016. <a href="https://doi.org/10.48550/arXiv.1506.01497">https://doi.org/10.48550/arXiv.1506.01497</a>.
</div>
<div id="ref-UnifiedPerceptualParsing2018xiao" class="csl-entry" role="listitem">
Xiao, Tete, Yingcheng Liu, Bolei Zhou, Yuning Jiang, and Jian Sun. 2018. <span>â€œUnified <span>Perceptual Parsing</span> for <span>Scene Understanding</span>.â€</span> July 26, 2018. <a href="https://doi.org/10.48550/arXiv.1807.10221">https://doi.org/10.48550/arXiv.1807.10221</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Â© CC-By Yuyang, 2025</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This page is built with â¤ï¸ and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




<script src="../../../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.js" defer="true"></script>
</body></html>